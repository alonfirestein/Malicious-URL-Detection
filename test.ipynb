{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T11:12:49.164356Z",
     "start_time": "2021-12-26T11:12:49.150351Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T11:14:23.899495Z",
     "start_time": "2021-12-26T11:14:23.364952Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./All.csv')\n",
    "df = df.sample(frac=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T11:14:36.522000Z",
     "start_time": "2021-12-26T11:14:36.113994Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 5 artists>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels,counts = np.unique(df[\"URL_Type_obf_Type\"],return_counts=True)\n",
    "plt.bar(labels,counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T11:22:15.142641Z",
     "start_time": "2021-12-26T11:22:15.097535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avgpathtokenlen             280\n",
       "NumberRate_DirectoryName     10\n",
       "NumberRate_FileName          10\n",
       "NumberRate_AfterPath          3\n",
       "Entropy_Filename            236\n",
       "Entropy_Extension            40\n",
       "Entropy_Afterpath             6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nans[(nans < 1000) & (nans > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T11:23:03.929786Z",
     "start_time": "2021-12-26T11:23:03.725808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Querylength</th>\n",
       "      <th>domain_token_count</th>\n",
       "      <th>path_token_count</th>\n",
       "      <th>avgdomaintokenlen</th>\n",
       "      <th>longdomaintokenlen</th>\n",
       "      <th>avgpathtokenlen</th>\n",
       "      <th>tld</th>\n",
       "      <th>charcompvowels</th>\n",
       "      <th>charcompace</th>\n",
       "      <th>ldl_url</th>\n",
       "      <th>...</th>\n",
       "      <th>SymbolCount_Directoryname</th>\n",
       "      <th>SymbolCount_FileName</th>\n",
       "      <th>SymbolCount_Extension</th>\n",
       "      <th>SymbolCount_Afterpath</th>\n",
       "      <th>Entropy_URL</th>\n",
       "      <th>Entropy_Domain</th>\n",
       "      <th>Entropy_Filename</th>\n",
       "      <th>Entropy_Extension</th>\n",
       "      <th>Entropy_Afterpath</th>\n",
       "      <th>URL_Type_obf_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12666</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>4.941176</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.611724</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.623330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10086</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>10</td>\n",
       "      <td>4.333334</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.745273</td>\n",
       "      <td>0.887436</td>\n",
       "      <td>0.881071</td>\n",
       "      <td>0.884088</td>\n",
       "      <td>0.900880</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5296</th>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.708451</td>\n",
       "      <td>0.745484</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32724</th>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>12</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.704049</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.706663</td>\n",
       "      <td>0.665256</td>\n",
       "      <td>0.796205</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22825</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.689956</td>\n",
       "      <td>0.728590</td>\n",
       "      <td>0.641068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.727919</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26949</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6.333334</td>\n",
       "      <td>13</td>\n",
       "      <td>7.666666</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.753500</td>\n",
       "      <td>0.801985</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23220</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.771971</td>\n",
       "      <td>0.684657</td>\n",
       "      <td>0.812689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10173</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.660523</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.649105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11467</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.659619</td>\n",
       "      <td>0.898227</td>\n",
       "      <td>0.737035</td>\n",
       "      <td>0.786351</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15026</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>10</td>\n",
       "      <td>4.333334</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.784516</td>\n",
       "      <td>0.798231</td>\n",
       "      <td>0.851321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36133 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Querylength  domain_token_count  path_token_count  avgdomaintokenlen  \\\n",
       "12666            0                   2                17           3.500000   \n",
       "10086           12                   2                 9           6.500000   \n",
       "5296            53                   3                16           6.000000   \n",
       "32724           29                   4                14           5.750000   \n",
       "22825           10                   2                11          12.000000   \n",
       "...            ...                 ...               ...                ...   \n",
       "26949            0                   3                 3           6.333334   \n",
       "23220            0                   2                 5           5.000000   \n",
       "10173            0                   2                12           3.500000   \n",
       "11467            0                   2                 7           3.000000   \n",
       "15026            0                   2                 6           6.500000   \n",
       "\n",
       "       longdomaintokenlen  avgpathtokenlen  tld  charcompvowels  charcompace  \\\n",
       "12666                   4         4.941176    2              31           25   \n",
       "10086                  10         4.333334    2              13            7   \n",
       "5296                   13         2.666667    3              23           12   \n",
       "32724                  12         3.666667    4              17           22   \n",
       "22825                  22         3.333333    2              17           18   \n",
       "...                   ...              ...  ...             ...          ...   \n",
       "26949                  13         7.666666    3               9            6   \n",
       "23220                   7        18.400000    2               8            7   \n",
       "10173                   4         3.750000    2              15            9   \n",
       "11467                   3         5.428571    2              17           14   \n",
       "15026                  10         4.333334    2               7            2   \n",
       "\n",
       "       ldl_url  ...  SymbolCount_Directoryname  SymbolCount_FileName  \\\n",
       "12666        0  ...                          1                     0   \n",
       "10086        1  ...                          3                     3   \n",
       "5296         0  ...                         -1                    -1   \n",
       "32724        3  ...                         11                     3   \n",
       "22825       14  ...                          9                     0   \n",
       "...        ...  ...                        ...                   ...   \n",
       "26949        2  ...                          1                     0   \n",
       "23220       12  ...                          3                     0   \n",
       "10173        0  ...                          1                     0   \n",
       "11467        0  ...                          2                     3   \n",
       "15026        0  ...                          2                     0   \n",
       "\n",
       "       SymbolCount_Extension  SymbolCount_Afterpath  Entropy_URL  \\\n",
       "12666                      0                     -1     0.611724   \n",
       "10086                      2                      1     0.745273   \n",
       "5296                      -1                     -1     0.708451   \n",
       "32724                      2                      7     0.704049   \n",
       "22825                      0                      4     0.689956   \n",
       "...                      ...                    ...          ...   \n",
       "26949                      0                     -1     0.753500   \n",
       "23220                      0                     -1     0.771971   \n",
       "10173                      0                     -1     0.660523   \n",
       "11467                      2                     -1     0.659619   \n",
       "15026                      0                     -1     0.784516   \n",
       "\n",
       "       Entropy_Domain  Entropy_Filename  Entropy_Extension  Entropy_Afterpath  \\\n",
       "12666        0.916667          0.623330           0.000000          -1.000000   \n",
       "10086        0.887436          0.881071           0.884088           0.900880   \n",
       "5296         0.745484         -1.000000          -1.000000          -1.000000   \n",
       "32724        0.791265          0.706663           0.665256           0.796205   \n",
       "22825        0.728590          0.641068           0.000000           0.727919   \n",
       "...               ...               ...                ...                ...   \n",
       "26949        0.801985          1.000000           0.000000          -1.000000   \n",
       "23220        0.684657          0.812689           0.000000          -1.000000   \n",
       "10173        0.916667          0.649105           0.000000          -1.000000   \n",
       "11467        0.898227          0.737035           0.786351          -1.000000   \n",
       "15026        0.798231          0.851321           0.000000          -1.000000   \n",
       "\n",
       "       URL_Type_obf_Type  \n",
       "12666             benign  \n",
       "10086             benign  \n",
       "5296          Defacement  \n",
       "32724               spam  \n",
       "22825           phishing  \n",
       "...                  ...  \n",
       "26949           phishing  \n",
       "23220           phishing  \n",
       "10173             benign  \n",
       "11467             benign  \n",
       "15026             benign  \n",
       "\n",
       "[36133 rows x 78 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nans = df.isna().sum()\n",
    "df = df.drop(list(nans[nans > 5000].index),axis=1)\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T11:32:32.999011Z",
     "start_time": "2021-12-26T11:32:32.945012Z"
    }
   },
   "outputs": [],
   "source": [
    "df['URL_Type_obf_Type'] = pd.Categorical(df['URL_Type_obf_Type'])\n",
    "df['URL_Type_obf_Type'] = df['URL_Type_obf_Type'].cat.codes\n",
    "X = df.drop(['URL_Type_obf_Type'], axis=1)\n",
    "y = df['URL_Type_obf_Type']\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T11:32:40.764382Z",
     "start_time": "2021-12-26T11:32:40.749387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36133, 77), (36133,))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T11:32:50.646706Z",
     "start_time": "2021-12-26T11:32:50.532703Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T11:24:03.919405Z",
     "start_time": "2021-12-26T11:24:03.891402Z"
    }
   },
   "outputs": [],
   "source": [
    "weights = pd.Series(y_train).value_counts().values / y_train.size\n",
    "all_weights = np.zeros(y_train.size)\n",
    "for label in np.unique(y_train):\n",
    "    all_weights[y_train == label] = weights[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T11:24:05.994704Z",
     "start_time": "2021-12-26T11:24:05.984718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20153757, 0.18604651, 0.20153757, ..., 0.2159139 , 0.20153757,\n",
       "       0.2159139 ])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:13:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-mlogloss:1.52425\tvalidation_1-mlogloss:1.52489\n",
      "Multiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mlogloss hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-mlogloss:1.45092\tvalidation_1-mlogloss:1.45222\n",
      "[2]\tvalidation_0-mlogloss:1.38367\tvalidation_1-mlogloss:1.38539\n",
      "[3]\tvalidation_0-mlogloss:1.32165\tvalidation_1-mlogloss:1.32401\n",
      "[4]\tvalidation_0-mlogloss:1.26374\tvalidation_1-mlogloss:1.26692\n",
      "[5]\tvalidation_0-mlogloss:1.21208\tvalidation_1-mlogloss:1.21580\n",
      "[6]\tvalidation_0-mlogloss:1.16401\tvalidation_1-mlogloss:1.16853\n",
      "[7]\tvalidation_0-mlogloss:1.11845\tvalidation_1-mlogloss:1.12332\n",
      "[8]\tvalidation_0-mlogloss:1.07694\tvalidation_1-mlogloss:1.08225\n",
      "[9]\tvalidation_0-mlogloss:1.03724\tvalidation_1-mlogloss:1.04300\n",
      "[10]\tvalidation_0-mlogloss:1.00171\tvalidation_1-mlogloss:1.00772\n",
      "[11]\tvalidation_0-mlogloss:0.96662\tvalidation_1-mlogloss:0.97323\n",
      "[12]\tvalidation_0-mlogloss:0.93376\tvalidation_1-mlogloss:0.94072\n",
      "[13]\tvalidation_0-mlogloss:0.90270\tvalidation_1-mlogloss:0.90989\n",
      "[14]\tvalidation_0-mlogloss:0.87425\tvalidation_1-mlogloss:0.88187\n",
      "[15]\tvalidation_0-mlogloss:0.84650\tvalidation_1-mlogloss:0.85440\n",
      "[16]\tvalidation_0-mlogloss:0.82013\tvalidation_1-mlogloss:0.82793\n",
      "[17]\tvalidation_0-mlogloss:0.79476\tvalidation_1-mlogloss:0.80273\n",
      "[18]\tvalidation_0-mlogloss:0.77049\tvalidation_1-mlogloss:0.77843\n",
      "[19]\tvalidation_0-mlogloss:0.74696\tvalidation_1-mlogloss:0.75494\n",
      "[20]\tvalidation_0-mlogloss:0.72440\tvalidation_1-mlogloss:0.73265\n",
      "[21]\tvalidation_0-mlogloss:0.70408\tvalidation_1-mlogloss:0.71244\n",
      "[22]\tvalidation_0-mlogloss:0.68360\tvalidation_1-mlogloss:0.69168\n",
      "[23]\tvalidation_0-mlogloss:0.66436\tvalidation_1-mlogloss:0.67288\n",
      "[24]\tvalidation_0-mlogloss:0.64635\tvalidation_1-mlogloss:0.65490\n",
      "[25]\tvalidation_0-mlogloss:0.62828\tvalidation_1-mlogloss:0.63706\n",
      "[26]\tvalidation_0-mlogloss:0.61099\tvalidation_1-mlogloss:0.62011\n",
      "[27]\tvalidation_0-mlogloss:0.59426\tvalidation_1-mlogloss:0.60380\n",
      "[28]\tvalidation_0-mlogloss:0.57861\tvalidation_1-mlogloss:0.58821\n",
      "[29]\tvalidation_0-mlogloss:0.56347\tvalidation_1-mlogloss:0.57346\n",
      "[30]\tvalidation_0-mlogloss:0.54919\tvalidation_1-mlogloss:0.55935\n",
      "[31]\tvalidation_0-mlogloss:0.53558\tvalidation_1-mlogloss:0.54593\n",
      "[32]\tvalidation_0-mlogloss:0.52216\tvalidation_1-mlogloss:0.53277\n",
      "[33]\tvalidation_0-mlogloss:0.51011\tvalidation_1-mlogloss:0.52058\n",
      "[34]\tvalidation_0-mlogloss:0.49845\tvalidation_1-mlogloss:0.50896\n",
      "[35]\tvalidation_0-mlogloss:0.48698\tvalidation_1-mlogloss:0.49774\n",
      "[36]\tvalidation_0-mlogloss:0.47618\tvalidation_1-mlogloss:0.48726\n",
      "[37]\tvalidation_0-mlogloss:0.46520\tvalidation_1-mlogloss:0.47640\n",
      "[38]\tvalidation_0-mlogloss:0.45503\tvalidation_1-mlogloss:0.46640\n",
      "[39]\tvalidation_0-mlogloss:0.44474\tvalidation_1-mlogloss:0.45653\n",
      "[40]\tvalidation_0-mlogloss:0.43494\tvalidation_1-mlogloss:0.44709\n",
      "[41]\tvalidation_0-mlogloss:0.42492\tvalidation_1-mlogloss:0.43740\n",
      "[42]\tvalidation_0-mlogloss:0.41606\tvalidation_1-mlogloss:0.42885\n",
      "[43]\tvalidation_0-mlogloss:0.40750\tvalidation_1-mlogloss:0.42068\n",
      "[44]\tvalidation_0-mlogloss:0.39835\tvalidation_1-mlogloss:0.41186\n",
      "[45]\tvalidation_0-mlogloss:0.39038\tvalidation_1-mlogloss:0.40394\n",
      "[46]\tvalidation_0-mlogloss:0.38282\tvalidation_1-mlogloss:0.39667\n",
      "[47]\tvalidation_0-mlogloss:0.37532\tvalidation_1-mlogloss:0.38938\n",
      "[48]\tvalidation_0-mlogloss:0.36825\tvalidation_1-mlogloss:0.38257\n",
      "[49]\tvalidation_0-mlogloss:0.36073\tvalidation_1-mlogloss:0.37532\n",
      "[50]\tvalidation_0-mlogloss:0.35447\tvalidation_1-mlogloss:0.36939\n",
      "[51]\tvalidation_0-mlogloss:0.34776\tvalidation_1-mlogloss:0.36315\n",
      "[52]\tvalidation_0-mlogloss:0.34160\tvalidation_1-mlogloss:0.35705\n",
      "[53]\tvalidation_0-mlogloss:0.33547\tvalidation_1-mlogloss:0.35111\n",
      "[54]\tvalidation_0-mlogloss:0.32928\tvalidation_1-mlogloss:0.34508\n",
      "[55]\tvalidation_0-mlogloss:0.32266\tvalidation_1-mlogloss:0.33867\n",
      "[56]\tvalidation_0-mlogloss:0.31722\tvalidation_1-mlogloss:0.33336\n",
      "[57]\tvalidation_0-mlogloss:0.31167\tvalidation_1-mlogloss:0.32797\n",
      "[58]\tvalidation_0-mlogloss:0.30637\tvalidation_1-mlogloss:0.32258\n",
      "[59]\tvalidation_0-mlogloss:0.30108\tvalidation_1-mlogloss:0.31736\n",
      "[60]\tvalidation_0-mlogloss:0.29581\tvalidation_1-mlogloss:0.31230\n",
      "[61]\tvalidation_0-mlogloss:0.29109\tvalidation_1-mlogloss:0.30769\n",
      "[62]\tvalidation_0-mlogloss:0.28651\tvalidation_1-mlogloss:0.30319\n",
      "[63]\tvalidation_0-mlogloss:0.28201\tvalidation_1-mlogloss:0.29870\n",
      "[64]\tvalidation_0-mlogloss:0.27759\tvalidation_1-mlogloss:0.29439\n",
      "[65]\tvalidation_0-mlogloss:0.27354\tvalidation_1-mlogloss:0.29054\n",
      "[66]\tvalidation_0-mlogloss:0.26910\tvalidation_1-mlogloss:0.28622\n",
      "[67]\tvalidation_0-mlogloss:0.26497\tvalidation_1-mlogloss:0.28226\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xgb = XGBClassifier(n_estimators=5000, learning_rate=0.05, gamma=0, subsample=0.7,\n",
    "                            objective=\"multi:softprob\",\n",
    "                            num_class=len(np.unique(y_train)),\n",
    "                            eval_metric=\"mlogloss\", random_state=93, use_label_encoder=False)\n",
    "xgb = xgb.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "                        early_stopping_rounds=10,\n",
    "                        sample_weight=all_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict classification report\n",
    "y_pred = xgb.predict(X_test)\n",
    "# print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"xgb_good\", \"wb\") as file:\n",
    "    pickle.dump(xgb, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T11:51:41.476342Z",
     "start_time": "2021-12-26T11:51:41.355341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 60)                4680      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 15)                465       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 5)                 80        \n",
      "=================================================================\n",
      "Total params: 7,055\n",
      "Trainable params: 7,055\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense,Dropout,Flatten\n",
    "model = Sequential()\n",
    "model.add(Dense(60, activation=\"relu\",input_shape=(77,)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(30, activation=\"relu\"))\n",
    "model.add(Dense(15, activation=\"relu\"))\n",
    "model.add(Dense(5, activation=\"softmax\"))\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),metrics=[\"accuracy\",tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T11:51:25.072083Z",
     "start_time": "2021-12-26T11:51:25.047880Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "y = np_utils.to_categorical(LabelEncoder().fit_transform(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T11:51:25.633317Z",
     "start_time": "2021-12-26T11:51:25.480323Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T11:55:58.382823Z",
     "start_time": "2021-12-26T11:52:18.880452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.8822 - accuracy: 0.6761 - recall_8: 0.5371 - precision_8: 0.7871 - val_loss: 0.7238 - val_accuracy: 0.7456 - val_recall_8: 0.6564 - val_precision_8: 0.8439\n",
      "Epoch 2/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.8225 - accuracy: 0.6980 - recall_8: 0.5828 - precision_8: 0.7999 - val_loss: 0.6792 - val_accuracy: 0.7586 - val_recall_8: 0.6672 - val_precision_8: 0.8493\n",
      "Epoch 3/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.7729 - accuracy: 0.7166 - recall_8: 0.6126 - precision_8: 0.8051 - val_loss: 0.6318 - val_accuracy: 0.7802 - val_recall_8: 0.6879 - val_precision_8: 0.8516\n",
      "Epoch 4/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.7357 - accuracy: 0.7331 - recall_8: 0.6387 - precision_8: 0.8166 - val_loss: 0.5973 - val_accuracy: 0.7871 - val_recall_8: 0.7056 - val_precision_8: 0.8628\n",
      "Epoch 5/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.6964 - accuracy: 0.7448 - recall_8: 0.6620 - precision_8: 0.8225 - val_loss: 0.5545 - val_accuracy: 0.7971 - val_recall_8: 0.7233 - val_precision_8: 0.8555\n",
      "Epoch 6/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.6703 - accuracy: 0.7516 - recall_8: 0.6729 - precision_8: 0.8246 - val_loss: 0.5324 - val_accuracy: 0.8163 - val_recall_8: 0.7356 - val_precision_8: 0.8772\n",
      "Epoch 7/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.6447 - accuracy: 0.7626 - recall_8: 0.6883 - precision_8: 0.8301 - val_loss: 0.4927 - val_accuracy: 0.8186 - val_recall_8: 0.7702 - val_precision_8: 0.8751\n",
      "Epoch 8/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.6226 - accuracy: 0.7731 - recall_8: 0.7041 - precision_8: 0.8368 - val_loss: 0.4684 - val_accuracy: 0.8370 - val_recall_8: 0.7825 - val_precision_8: 0.8930\n",
      "Epoch 9/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.5961 - accuracy: 0.7860 - recall_8: 0.7218 - precision_8: 0.8440 - val_loss: 0.4605 - val_accuracy: 0.8463 - val_recall_8: 0.7756 - val_precision_8: 0.9049\n",
      "Epoch 10/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.5696 - accuracy: 0.7925 - recall_8: 0.7354 - precision_8: 0.8498 - val_loss: 0.4340 - val_accuracy: 0.8586 - val_recall_8: 0.8094 - val_precision_8: 0.9008\n",
      "Epoch 11/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.5565 - accuracy: 0.8004 - recall_8: 0.7428 - precision_8: 0.8530 - val_loss: 0.4100 - val_accuracy: 0.8616 - val_recall_8: 0.8086 - val_precision_8: 0.9156\n",
      "Epoch 12/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.5355 - accuracy: 0.8072 - recall_8: 0.7551 - precision_8: 0.8567 - val_loss: 0.3994 - val_accuracy: 0.8678 - val_recall_8: 0.8178 - val_precision_8: 0.9149\n",
      "Epoch 13/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.8101 - recall_8: 0.7593 - precision_8: 0.8569 - val_loss: 0.4011 - val_accuracy: 0.8601 - val_recall_8: 0.8117 - val_precision_8: 0.8980\n",
      "Epoch 14/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.5137 - accuracy: 0.8152 - recall_8: 0.7688 - precision_8: 0.8614 - val_loss: 0.3781 - val_accuracy: 0.8686 - val_recall_8: 0.8255 - val_precision_8: 0.9148\n",
      "Epoch 15/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.5008 - accuracy: 0.8186 - recall_8: 0.7713 - precision_8: 0.8629 - val_loss: 0.3534 - val_accuracy: 0.8824 - val_recall_8: 0.8409 - val_precision_8: 0.9155\n",
      "Epoch 16/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.4887 - accuracy: 0.8238 - recall_8: 0.7828 - precision_8: 0.8675 - val_loss: 0.3463 - val_accuracy: 0.8870 - val_recall_8: 0.8501 - val_precision_8: 0.9201\n",
      "Epoch 17/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.8288 - recall_8: 0.7891 - precision_8: 0.8682 - val_loss: 0.3364 - val_accuracy: 0.8924 - val_recall_8: 0.8670 - val_precision_8: 0.9284\n",
      "Epoch 18/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.8297 - recall_8: 0.7894 - precision_8: 0.8720 - val_loss: 0.3487 - val_accuracy: 0.8824 - val_recall_8: 0.8486 - val_precision_8: 0.9231\n",
      "Epoch 19/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.4707 - accuracy: 0.8302 - recall_8: 0.7877 - precision_8: 0.8676 - val_loss: 0.3302 - val_accuracy: 0.8878 - val_recall_8: 0.8616 - val_precision_8: 0.9226\n",
      "Epoch 20/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.4607 - accuracy: 0.8339 - recall_8: 0.7936 - precision_8: 0.8720 - val_loss: 0.3227 - val_accuracy: 0.8878 - val_recall_8: 0.8563 - val_precision_8: 0.9176\n",
      "Epoch 21/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.8382 - recall_8: 0.7995 - precision_8: 0.8767 - val_loss: 0.3210 - val_accuracy: 0.8885 - val_recall_8: 0.8563 - val_precision_8: 0.9131\n",
      "Epoch 22/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.4431 - accuracy: 0.8400 - recall_8: 0.8041 - precision_8: 0.8747 - val_loss: 0.3206 - val_accuracy: 0.8947 - val_recall_8: 0.8686 - val_precision_8: 0.9224\n",
      "Epoch 23/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.4311 - accuracy: 0.8430 - recall_8: 0.8050 - precision_8: 0.8773 - val_loss: 0.3251 - val_accuracy: 0.8816 - val_recall_8: 0.8632 - val_precision_8: 0.9130\n",
      "Epoch 24/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.4359 - accuracy: 0.8424 - recall_8: 0.8062 - precision_8: 0.8776 - val_loss: 0.3085 - val_accuracy: 0.8978 - val_recall_8: 0.8770 - val_precision_8: 0.9216\n",
      "Epoch 25/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8477 - recall_8: 0.8111 - precision_8: 0.8828 - val_loss: 0.3052 - val_accuracy: 0.8985 - val_recall_8: 0.8739 - val_precision_8: 0.9192\n",
      "Epoch 26/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.4227 - accuracy: 0.8481 - recall_8: 0.8135 - precision_8: 0.8806 - val_loss: 0.3036 - val_accuracy: 0.8924 - val_recall_8: 0.8701 - val_precision_8: 0.9114\n",
      "Epoch 27/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.4176 - accuracy: 0.8515 - recall_8: 0.8171 - precision_8: 0.8855 - val_loss: 0.3036 - val_accuracy: 0.9024 - val_recall_8: 0.8709 - val_precision_8: 0.9219\n",
      "Epoch 28/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.4113 - accuracy: 0.8543 - recall_8: 0.8205 - precision_8: 0.8868 - val_loss: 0.2893 - val_accuracy: 0.9008 - val_recall_8: 0.8762 - val_precision_8: 0.9246\n",
      "Epoch 29/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8523 - recall_8: 0.8196 - precision_8: 0.8850 - val_loss: 0.2971 - val_accuracy: 0.8924 - val_recall_8: 0.8686 - val_precision_8: 0.9172\n",
      "Epoch 30/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.3988 - accuracy: 0.8573 - recall_8: 0.8250 - precision_8: 0.8891 - val_loss: 0.2865 - val_accuracy: 0.9047 - val_recall_8: 0.8855 - val_precision_8: 0.9238\n",
      "Epoch 31/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.4004 - accuracy: 0.8557 - recall_8: 0.8241 - precision_8: 0.8872 - val_loss: 0.2969 - val_accuracy: 0.9016 - val_recall_8: 0.8832 - val_precision_8: 0.9177\n",
      "Epoch 32/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.3915 - accuracy: 0.8577 - recall_8: 0.8276 - precision_8: 0.8876 - val_loss: 0.2865 - val_accuracy: 0.9001 - val_recall_8: 0.8809 - val_precision_8: 0.9242\n",
      "Epoch 33/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.3892 - accuracy: 0.8592 - recall_8: 0.8297 - precision_8: 0.8896 - val_loss: 0.2842 - val_accuracy: 0.9024 - val_recall_8: 0.8786 - val_precision_8: 0.9248\n",
      "Epoch 34/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.3886 - accuracy: 0.8600 - recall_8: 0.8292 - precision_8: 0.8903 - val_loss: 0.2887 - val_accuracy: 0.9032 - val_recall_8: 0.8801 - val_precision_8: 0.9204\n",
      "Epoch 35/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.3800 - accuracy: 0.8649 - recall_8: 0.8346 - precision_8: 0.8937 - val_loss: 0.2843 - val_accuracy: 0.9062 - val_recall_8: 0.8924 - val_precision_8: 0.9214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3817 - accuracy: 0.8617 - recall_8: 0.8331 - precision_8: 0.8912 - val_loss: 0.2885 - val_accuracy: 0.8932 - val_recall_8: 0.8824 - val_precision_8: 0.9162\n",
      "Epoch 37/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3791 - accuracy: 0.8672 - recall_8: 0.8379 - precision_8: 0.8935 - val_loss: 0.2924 - val_accuracy: 0.9024 - val_recall_8: 0.8816 - val_precision_8: 0.9220\n",
      "Epoch 38/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.3722 - accuracy: 0.8662 - recall_8: 0.8383 - precision_8: 0.8944 - val_loss: 0.2780 - val_accuracy: 0.9085 - val_recall_8: 0.8932 - val_precision_8: 0.9274\n",
      "Epoch 39/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3643 - accuracy: 0.8665 - recall_8: 0.8388 - precision_8: 0.8953 - val_loss: 0.2634 - val_accuracy: 0.9070 - val_recall_8: 0.8932 - val_precision_8: 0.9274\n",
      "Epoch 40/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.3701 - accuracy: 0.8677 - recall_8: 0.8411 - precision_8: 0.8954 - val_loss: 0.2783 - val_accuracy: 0.9055 - val_recall_8: 0.8824 - val_precision_8: 0.9258\n",
      "Epoch 41/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3736 - accuracy: 0.8673 - recall_8: 0.8383 - precision_8: 0.8947 - val_loss: 0.2732 - val_accuracy: 0.9047 - val_recall_8: 0.8924 - val_precision_8: 0.9222\n",
      "Epoch 42/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3709 - accuracy: 0.8669 - recall_8: 0.8389 - precision_8: 0.8958 - val_loss: 0.2721 - val_accuracy: 0.9055 - val_recall_8: 0.8909 - val_precision_8: 0.9228\n",
      "Epoch 43/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3618 - accuracy: 0.8689 - recall_8: 0.8426 - precision_8: 0.8979 - val_loss: 0.2651 - val_accuracy: 0.9070 - val_recall_8: 0.8878 - val_precision_8: 0.9262\n",
      "Epoch 44/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3680 - accuracy: 0.8687 - recall_8: 0.8410 - precision_8: 0.8961 - val_loss: 0.2658 - val_accuracy: 0.9116 - val_recall_8: 0.8947 - val_precision_8: 0.9334\n",
      "Epoch 45/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3524 - accuracy: 0.8744 - recall_8: 0.8479 - precision_8: 0.9013 - val_loss: 0.2671 - val_accuracy: 0.9078 - val_recall_8: 0.8939 - val_precision_8: 0.9267\n",
      "Epoch 46/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.3568 - accuracy: 0.8734 - recall_8: 0.8468 - precision_8: 0.8998 - val_loss: 0.2727 - val_accuracy: 0.9055 - val_recall_8: 0.8932 - val_precision_8: 0.9289\n",
      "Epoch 47/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.3524 - accuracy: 0.8746 - recall_8: 0.8504 - precision_8: 0.9000 - val_loss: 0.2686 - val_accuracy: 0.9008 - val_recall_8: 0.8824 - val_precision_8: 0.9147\n",
      "Epoch 48/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.3566 - accuracy: 0.8723 - recall_8: 0.8471 - precision_8: 0.9001 - val_loss: 0.2624 - val_accuracy: 0.9147 - val_recall_8: 0.9008 - val_precision_8: 0.9346\n",
      "Epoch 49/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.3488 - accuracy: 0.8757 - recall_8: 0.8503 - precision_8: 0.9022 - val_loss: 0.2673 - val_accuracy: 0.9024 - val_recall_8: 0.8893 - val_precision_8: 0.9249\n",
      "Epoch 50/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.3477 - accuracy: 0.8764 - recall_8: 0.8515 - precision_8: 0.9017 - val_loss: 0.2591 - val_accuracy: 0.9085 - val_recall_8: 0.9008 - val_precision_8: 0.9272\n",
      "Epoch 51/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8780 - recall_8: 0.8527 - precision_8: 0.9028 - val_loss: 0.2573 - val_accuracy: 0.9139 - val_recall_8: 0.8993 - val_precision_8: 0.9278\n",
      "Epoch 52/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.3435 - accuracy: 0.8777 - recall_8: 0.8532 - precision_8: 0.9021 - val_loss: 0.2705 - val_accuracy: 0.9085 - val_recall_8: 0.8947 - val_precision_8: 0.9253\n",
      "Epoch 53/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3422 - accuracy: 0.8777 - recall_8: 0.8536 - precision_8: 0.9015 - val_loss: 0.2736 - val_accuracy: 0.9108 - val_recall_8: 0.8939 - val_precision_8: 0.9297\n",
      "Epoch 54/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3422 - accuracy: 0.8782 - recall_8: 0.8527 - precision_8: 0.9045 - val_loss: 0.2589 - val_accuracy: 0.9116 - val_recall_8: 0.9016 - val_precision_8: 0.9229\n",
      "Epoch 55/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3365 - accuracy: 0.8812 - recall_8: 0.8578 - precision_8: 0.9057 - val_loss: 0.2806 - val_accuracy: 0.9024 - val_recall_8: 0.8939 - val_precision_8: 0.9223\n",
      "Epoch 56/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3407 - accuracy: 0.8763 - recall_8: 0.8530 - precision_8: 0.9019 - val_loss: 0.2621 - val_accuracy: 0.9101 - val_recall_8: 0.8970 - val_precision_8: 0.9211\n",
      "Epoch 57/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3386 - accuracy: 0.8814 - recall_8: 0.8568 - precision_8: 0.9036 - val_loss: 0.2609 - val_accuracy: 0.9139 - val_recall_8: 0.8947 - val_precision_8: 0.9275\n",
      "Epoch 58/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.3357 - accuracy: 0.8792 - recall_8: 0.8557 - precision_8: 0.9029 - val_loss: 0.2682 - val_accuracy: 0.9093 - val_recall_8: 0.8947 - val_precision_8: 0.9282\n",
      "Epoch 59/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3342 - accuracy: 0.8815 - recall_8: 0.8583 - precision_8: 0.9050 - val_loss: 0.2658 - val_accuracy: 0.9085 - val_recall_8: 0.8955 - val_precision_8: 0.9239\n",
      "Epoch 60/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3301 - accuracy: 0.8813 - recall_8: 0.8598 - precision_8: 0.9054 - val_loss: 0.2551 - val_accuracy: 0.9185 - val_recall_8: 0.9047 - val_precision_8: 0.9341\n",
      "Epoch 61/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3266 - accuracy: 0.8833 - recall_8: 0.8607 - precision_8: 0.9076 - val_loss: 0.2520 - val_accuracy: 0.9055 - val_recall_8: 0.8947 - val_precision_8: 0.9194\n",
      "Epoch 62/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.3224 - accuracy: 0.8852 - recall_8: 0.8637 - precision_8: 0.9076 - val_loss: 0.2392 - val_accuracy: 0.9216 - val_recall_8: 0.9078 - val_precision_8: 0.9343\n",
      "Epoch 63/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3247 - accuracy: 0.8837 - recall_8: 0.8617 - precision_8: 0.9068 - val_loss: 0.2705 - val_accuracy: 0.9078 - val_recall_8: 0.8901 - val_precision_8: 0.9227\n",
      "Epoch 64/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.3187 - accuracy: 0.8849 - recall_8: 0.8647 - precision_8: 0.9099 - val_loss: 0.2487 - val_accuracy: 0.9116 - val_recall_8: 0.9039 - val_precision_8: 0.9267\n",
      "Epoch 65/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3315 - accuracy: 0.8805 - recall_8: 0.8589 - precision_8: 0.9038 - val_loss: 0.2480 - val_accuracy: 0.9201 - val_recall_8: 0.9047 - val_precision_8: 0.9371\n",
      "Epoch 66/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3244 - accuracy: 0.8849 - recall_8: 0.8621 - precision_8: 0.9080 - val_loss: 0.2398 - val_accuracy: 0.9178 - val_recall_8: 0.9039 - val_precision_8: 0.9296\n",
      "Epoch 67/2500\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.3214 - accuracy: 0.8854 - recall_8: 0.8634 - precision_8: 0.9086 - val_loss: 0.2454 - val_accuracy: 0.9208 - val_recall_8: 0.9085 - val_precision_8: 0.9307\n",
      "Epoch 68/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3280 - accuracy: 0.8827 - recall_8: 0.8616 - precision_8: 0.9057 - val_loss: 0.2444 - val_accuracy: 0.9193 - val_recall_8: 0.9085 - val_precision_8: 0.9322\n",
      "Epoch 69/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3218 - accuracy: 0.8844 - recall_8: 0.8644 - precision_8: 0.9087 - val_loss: 0.2453 - val_accuracy: 0.9162 - val_recall_8: 0.9047 - val_precision_8: 0.9349\n",
      "Epoch 70/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3151 - accuracy: 0.8886 - recall_8: 0.8672 - precision_8: 0.9098 - val_loss: 0.2596 - val_accuracy: 0.9139 - val_recall_8: 0.9024 - val_precision_8: 0.9281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.3208 - accuracy: 0.8852 - recall_8: 0.8645 - precision_8: 0.9083 - val_loss: 0.2455 - val_accuracy: 0.9154 - val_recall_8: 0.9062 - val_precision_8: 0.9283\n",
      "Epoch 72/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3164 - accuracy: 0.8860 - recall_8: 0.8654 - precision_8: 0.9077 - val_loss: 0.2421 - val_accuracy: 0.9262 - val_recall_8: 0.9116 - val_precision_8: 0.9383\n",
      "Epoch 73/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3099 - accuracy: 0.8899 - recall_8: 0.8696 - precision_8: 0.9117 - val_loss: 0.2467 - val_accuracy: 0.9201 - val_recall_8: 0.9116 - val_precision_8: 0.9331\n",
      "Epoch 74/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3213 - accuracy: 0.8826 - recall_8: 0.8623 - precision_8: 0.9067 - val_loss: 0.2484 - val_accuracy: 0.9185 - val_recall_8: 0.9001 - val_precision_8: 0.9323\n",
      "Epoch 75/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.3045 - accuracy: 0.8905 - recall_8: 0.8705 - precision_8: 0.9106 - val_loss: 0.2395 - val_accuracy: 0.9162 - val_recall_8: 0.9093 - val_precision_8: 0.9344\n",
      "Epoch 76/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.3142 - accuracy: 0.8866 - recall_8: 0.8646 - precision_8: 0.9093 - val_loss: 0.2444 - val_accuracy: 0.9139 - val_recall_8: 0.8985 - val_precision_8: 0.9278\n",
      "Epoch 77/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.3076 - accuracy: 0.8894 - recall_8: 0.8685 - precision_8: 0.9115 - val_loss: 0.2396 - val_accuracy: 0.9170 - val_recall_8: 0.9008 - val_precision_8: 0.9302\n",
      "Epoch 78/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.3078 - accuracy: 0.8899 - recall_8: 0.8710 - precision_8: 0.9114 - val_loss: 0.2409 - val_accuracy: 0.9178 - val_recall_8: 0.9032 - val_precision_8: 0.9340\n",
      "Epoch 79/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2960 - accuracy: 0.8933 - recall_8: 0.8743 - precision_8: 0.9143 - val_loss: 0.2278 - val_accuracy: 0.9231 - val_recall_8: 0.9101 - val_precision_8: 0.9367\n",
      "Epoch 80/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2999 - accuracy: 0.8922 - recall_8: 0.8737 - precision_8: 0.9140 - val_loss: 0.2346 - val_accuracy: 0.9216 - val_recall_8: 0.9093 - val_precision_8: 0.9389\n",
      "Epoch 81/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3029 - accuracy: 0.8916 - recall_8: 0.8734 - precision_8: 0.9117 - val_loss: 0.2346 - val_accuracy: 0.9170 - val_recall_8: 0.9055 - val_precision_8: 0.9283\n",
      "Epoch 82/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3077 - accuracy: 0.8887 - recall_8: 0.8696 - precision_8: 0.9105 - val_loss: 0.2280 - val_accuracy: 0.9208 - val_recall_8: 0.9101 - val_precision_8: 0.9352\n",
      "Epoch 83/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3008 - accuracy: 0.8937 - recall_8: 0.8745 - precision_8: 0.9144 - val_loss: 0.2317 - val_accuracy: 0.9185 - val_recall_8: 0.9055 - val_precision_8: 0.9327\n",
      "Epoch 84/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3012 - accuracy: 0.8918 - recall_8: 0.8734 - precision_8: 0.9140 - val_loss: 0.2279 - val_accuracy: 0.9162 - val_recall_8: 0.9070 - val_precision_8: 0.9321\n",
      "Epoch 85/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.3076 - accuracy: 0.8874 - recall_8: 0.8678 - precision_8: 0.9087 - val_loss: 0.2479 - val_accuracy: 0.9139 - val_recall_8: 0.9032 - val_precision_8: 0.9259\n",
      "Epoch 86/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3081 - accuracy: 0.8907 - recall_8: 0.8710 - precision_8: 0.9115 - val_loss: 0.2430 - val_accuracy: 0.9139 - val_recall_8: 0.9070 - val_precision_8: 0.9284\n",
      "Epoch 87/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.3111 - accuracy: 0.8877 - recall_8: 0.8696 - precision_8: 0.9084 - val_loss: 0.2434 - val_accuracy: 0.9154 - val_recall_8: 0.9078 - val_precision_8: 0.9255\n",
      "Epoch 88/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2979 - accuracy: 0.8941 - recall_8: 0.8760 - precision_8: 0.9130 - val_loss: 0.2238 - val_accuracy: 0.9224 - val_recall_8: 0.9154 - val_precision_8: 0.9363\n",
      "Epoch 89/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2996 - accuracy: 0.8942 - recall_8: 0.8752 - precision_8: 0.9130 - val_loss: 0.2260 - val_accuracy: 0.9231 - val_recall_8: 0.9070 - val_precision_8: 0.9373\n",
      "Epoch 90/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3001 - accuracy: 0.8929 - recall_8: 0.8727 - precision_8: 0.9129 - val_loss: 0.2357 - val_accuracy: 0.9185 - val_recall_8: 0.9101 - val_precision_8: 0.9360\n",
      "Epoch 91/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2936 - accuracy: 0.8935 - recall_8: 0.8758 - precision_8: 0.9137 - val_loss: 0.2267 - val_accuracy: 0.9231 - val_recall_8: 0.9154 - val_precision_8: 0.9371\n",
      "Epoch 92/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2870 - accuracy: 0.8981 - recall_8: 0.8805 - precision_8: 0.9164 - val_loss: 0.2280 - val_accuracy: 0.9216 - val_recall_8: 0.9116 - val_precision_8: 0.9309\n",
      "Epoch 93/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2994 - accuracy: 0.8918 - recall_8: 0.8748 - precision_8: 0.9124 - val_loss: 0.2223 - val_accuracy: 0.9247 - val_recall_8: 0.9116 - val_precision_8: 0.9361\n",
      "Epoch 94/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2947 - accuracy: 0.8936 - recall_8: 0.8753 - precision_8: 0.9135 - val_loss: 0.2256 - val_accuracy: 0.9208 - val_recall_8: 0.9116 - val_precision_8: 0.9339\n",
      "Epoch 95/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2963 - accuracy: 0.8933 - recall_8: 0.8731 - precision_8: 0.9124 - val_loss: 0.2250 - val_accuracy: 0.9201 - val_recall_8: 0.9093 - val_precision_8: 0.9352\n",
      "Epoch 96/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2898 - accuracy: 0.8967 - recall_8: 0.8792 - precision_8: 0.9168 - val_loss: 0.2234 - val_accuracy: 0.9208 - val_recall_8: 0.9062 - val_precision_8: 0.9342\n",
      "Epoch 97/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2921 - accuracy: 0.8948 - recall_8: 0.8759 - precision_8: 0.9135 - val_loss: 0.2197 - val_accuracy: 0.9239 - val_recall_8: 0.9093 - val_precision_8: 0.9404\n",
      "Epoch 98/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2975 - accuracy: 0.8928 - recall_8: 0.8751 - precision_8: 0.9136 - val_loss: 0.2251 - val_accuracy: 0.9162 - val_recall_8: 0.9078 - val_precision_8: 0.9343\n",
      "Epoch 99/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2901 - accuracy: 0.8949 - recall_8: 0.8768 - precision_8: 0.9140 - val_loss: 0.2281 - val_accuracy: 0.9170 - val_recall_8: 0.9055 - val_precision_8: 0.9357\n",
      "Epoch 100/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2921 - accuracy: 0.8948 - recall_8: 0.8775 - precision_8: 0.9154 - val_loss: 0.2250 - val_accuracy: 0.9216 - val_recall_8: 0.9131 - val_precision_8: 0.9347\n",
      "Epoch 101/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2888 - accuracy: 0.8956 - recall_8: 0.8765 - precision_8: 0.9154 - val_loss: 0.2191 - val_accuracy: 0.9201 - val_recall_8: 0.9085 - val_precision_8: 0.9359\n",
      "Epoch 102/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2860 - accuracy: 0.8976 - recall_8: 0.8809 - precision_8: 0.9157 - val_loss: 0.2290 - val_accuracy: 0.9170 - val_recall_8: 0.9055 - val_precision_8: 0.9283\n",
      "Epoch 103/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2877 - accuracy: 0.8944 - recall_8: 0.8776 - precision_8: 0.9144 - val_loss: 0.2257 - val_accuracy: 0.9231 - val_recall_8: 0.9124 - val_precision_8: 0.9339\n",
      "Epoch 104/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2880 - accuracy: 0.8952 - recall_8: 0.8769 - precision_8: 0.9137 - val_loss: 0.2292 - val_accuracy: 0.9170 - val_recall_8: 0.9139 - val_precision_8: 0.9246\n",
      "Epoch 105/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2902 - accuracy: 0.8972 - recall_8: 0.8806 - precision_8: 0.9162 - val_loss: 0.2203 - val_accuracy: 0.9239 - val_recall_8: 0.9147 - val_precision_8: 0.9385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2973 - accuracy: 0.8935 - recall_8: 0.8770 - precision_8: 0.9135 - val_loss: 0.2378 - val_accuracy: 0.9116 - val_recall_8: 0.8962 - val_precision_8: 0.9283\n",
      "Epoch 107/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2921 - accuracy: 0.8945 - recall_8: 0.8760 - precision_8: 0.9139 - val_loss: 0.2190 - val_accuracy: 0.9201 - val_recall_8: 0.9108 - val_precision_8: 0.9338\n",
      "Epoch 108/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2818 - accuracy: 0.8995 - recall_8: 0.8829 - precision_8: 0.9172 - val_loss: 0.2205 - val_accuracy: 0.9239 - val_recall_8: 0.9139 - val_precision_8: 0.9377\n",
      "Epoch 109/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2835 - accuracy: 0.8985 - recall_8: 0.8815 - precision_8: 0.9158 - val_loss: 0.2134 - val_accuracy: 0.9224 - val_recall_8: 0.9147 - val_precision_8: 0.9415\n",
      "Epoch 110/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2838 - accuracy: 0.8963 - recall_8: 0.8794 - precision_8: 0.9155 - val_loss: 0.2126 - val_accuracy: 0.9308 - val_recall_8: 0.9185 - val_precision_8: 0.9447\n",
      "Epoch 111/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2810 - accuracy: 0.8987 - recall_8: 0.8808 - precision_8: 0.9154 - val_loss: 0.2134 - val_accuracy: 0.9262 - val_recall_8: 0.9162 - val_precision_8: 0.9378\n",
      "Epoch 112/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2817 - accuracy: 0.8980 - recall_8: 0.8802 - precision_8: 0.9155 - val_loss: 0.2260 - val_accuracy: 0.9193 - val_recall_8: 0.9101 - val_precision_8: 0.9308\n",
      "Epoch 113/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2781 - accuracy: 0.8988 - recall_8: 0.8819 - precision_8: 0.9178 - val_loss: 0.2121 - val_accuracy: 0.9201 - val_recall_8: 0.9101 - val_precision_8: 0.9323\n",
      "Epoch 114/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2811 - accuracy: 0.9009 - recall_8: 0.8852 - precision_8: 0.9182 - val_loss: 0.2147 - val_accuracy: 0.9247 - val_recall_8: 0.9147 - val_precision_8: 0.9392\n",
      "Epoch 115/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2783 - accuracy: 0.9000 - recall_8: 0.8837 - precision_8: 0.9184 - val_loss: 0.2202 - val_accuracy: 0.9162 - val_recall_8: 0.9101 - val_precision_8: 0.9301\n",
      "Epoch 116/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2810 - accuracy: 0.8987 - recall_8: 0.8821 - precision_8: 0.9158 - val_loss: 0.2124 - val_accuracy: 0.9239 - val_recall_8: 0.9147 - val_precision_8: 0.9370\n",
      "Epoch 117/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2748 - accuracy: 0.9005 - recall_8: 0.8831 - precision_8: 0.9180 - val_loss: 0.2125 - val_accuracy: 0.9216 - val_recall_8: 0.9055 - val_precision_8: 0.9320\n",
      "Epoch 118/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2795 - accuracy: 0.8985 - recall_8: 0.8832 - precision_8: 0.9165 - val_loss: 0.2106 - val_accuracy: 0.9293 - val_recall_8: 0.9201 - val_precision_8: 0.9396\n",
      "Epoch 119/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2798 - accuracy: 0.8980 - recall_8: 0.8807 - precision_8: 0.9147 - val_loss: 0.2078 - val_accuracy: 0.9239 - val_recall_8: 0.9108 - val_precision_8: 0.9360\n",
      "Epoch 120/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2754 - accuracy: 0.9016 - recall_8: 0.8868 - precision_8: 0.9190 - val_loss: 0.2220 - val_accuracy: 0.9254 - val_recall_8: 0.9139 - val_precision_8: 0.9347\n",
      "Epoch 121/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2802 - accuracy: 0.8984 - recall_8: 0.8810 - precision_8: 0.9156 - val_loss: 0.2105 - val_accuracy: 0.9216 - val_recall_8: 0.9131 - val_precision_8: 0.9362\n",
      "Epoch 122/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2820 - accuracy: 0.8997 - recall_8: 0.8835 - precision_8: 0.9174 - val_loss: 0.2210 - val_accuracy: 0.9208 - val_recall_8: 0.9116 - val_precision_8: 0.9346\n",
      "Epoch 123/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2781 - accuracy: 0.8999 - recall_8: 0.8840 - precision_8: 0.9182 - val_loss: 0.2064 - val_accuracy: 0.9308 - val_recall_8: 0.9270 - val_precision_8: 0.9466\n",
      "Epoch 124/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2810 - accuracy: 0.9003 - recall_8: 0.8839 - precision_8: 0.9163 - val_loss: 0.2226 - val_accuracy: 0.9216 - val_recall_8: 0.9147 - val_precision_8: 0.9297\n",
      "Epoch 125/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2825 - accuracy: 0.8970 - recall_8: 0.8811 - precision_8: 0.9159 - val_loss: 0.2042 - val_accuracy: 0.9285 - val_recall_8: 0.9178 - val_precision_8: 0.9394\n",
      "Epoch 126/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2752 - accuracy: 0.9027 - recall_8: 0.8854 - precision_8: 0.9191 - val_loss: 0.2190 - val_accuracy: 0.9201 - val_recall_8: 0.9078 - val_precision_8: 0.9307\n",
      "Epoch 127/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2760 - accuracy: 0.9021 - recall_8: 0.8870 - precision_8: 0.9190 - val_loss: 0.2133 - val_accuracy: 0.9270 - val_recall_8: 0.9154 - val_precision_8: 0.9445\n",
      "Epoch 128/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2687 - accuracy: 0.9047 - recall_8: 0.8893 - precision_8: 0.9212 - val_loss: 0.2122 - val_accuracy: 0.9301 - val_recall_8: 0.9178 - val_precision_8: 0.9424\n",
      "Epoch 129/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2743 - accuracy: 0.9003 - recall_8: 0.8852 - precision_8: 0.9178 - val_loss: 0.2027 - val_accuracy: 0.9285 - val_recall_8: 0.9224 - val_precision_8: 0.9382\n",
      "Epoch 130/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2777 - accuracy: 0.9001 - recall_8: 0.8845 - precision_8: 0.9172 - val_loss: 0.2036 - val_accuracy: 0.9262 - val_recall_8: 0.9147 - val_precision_8: 0.9400\n",
      "Epoch 131/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2744 - accuracy: 0.9031 - recall_8: 0.8861 - precision_8: 0.9188 - val_loss: 0.2194 - val_accuracy: 0.9270 - val_recall_8: 0.9201 - val_precision_8: 0.9344\n",
      "Epoch 132/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2747 - accuracy: 0.8996 - recall_8: 0.8837 - precision_8: 0.9159 - val_loss: 0.2221 - val_accuracy: 0.9193 - val_recall_8: 0.9055 - val_precision_8: 0.9305\n",
      "Epoch 133/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2696 - accuracy: 0.9033 - recall_8: 0.8888 - precision_8: 0.9188 - val_loss: 0.2227 - val_accuracy: 0.9131 - val_recall_8: 0.9047 - val_precision_8: 0.9224\n",
      "Epoch 134/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2759 - accuracy: 0.9012 - recall_8: 0.8852 - precision_8: 0.9192 - val_loss: 0.2132 - val_accuracy: 0.9208 - val_recall_8: 0.9116 - val_precision_8: 0.9346\n",
      "Epoch 135/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2693 - accuracy: 0.9042 - recall_8: 0.8874 - precision_8: 0.9214 - val_loss: 0.2096 - val_accuracy: 0.9208 - val_recall_8: 0.9170 - val_precision_8: 0.9357\n",
      "Epoch 136/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2770 - accuracy: 0.9020 - recall_8: 0.8859 - precision_8: 0.9183 - val_loss: 0.2175 - val_accuracy: 0.9216 - val_recall_8: 0.9108 - val_precision_8: 0.9316\n",
      "Epoch 137/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2741 - accuracy: 0.9030 - recall_8: 0.8880 - precision_8: 0.9201 - val_loss: 0.1981 - val_accuracy: 0.9301 - val_recall_8: 0.9216 - val_precision_8: 0.9375\n",
      "Epoch 138/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2636 - accuracy: 0.9041 - recall_8: 0.8881 - precision_8: 0.9209 - val_loss: 0.2090 - val_accuracy: 0.9293 - val_recall_8: 0.9208 - val_precision_8: 0.9455\n",
      "Epoch 139/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2672 - accuracy: 0.9060 - recall_8: 0.8903 - precision_8: 0.9209 - val_loss: 0.2066 - val_accuracy: 0.9285 - val_recall_8: 0.9178 - val_precision_8: 0.9372\n",
      "Epoch 140/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2663 - accuracy: 0.9047 - recall_8: 0.8902 - precision_8: 0.9215 - val_loss: 0.2220 - val_accuracy: 0.9193 - val_recall_8: 0.9093 - val_precision_8: 0.9344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2672 - accuracy: 0.9040 - recall_8: 0.8890 - precision_8: 0.9208 - val_loss: 0.2038 - val_accuracy: 0.9331 - val_recall_8: 0.9239 - val_precision_8: 0.9427\n",
      "Epoch 142/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2699 - accuracy: 0.9019 - recall_8: 0.8856 - precision_8: 0.9195 - val_loss: 0.2190 - val_accuracy: 0.9239 - val_recall_8: 0.9185 - val_precision_8: 0.9336\n",
      "Epoch 143/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2667 - accuracy: 0.9049 - recall_8: 0.8893 - precision_8: 0.9210 - val_loss: 0.2033 - val_accuracy: 0.9285 - val_recall_8: 0.9178 - val_precision_8: 0.9416\n",
      "Epoch 144/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2657 - accuracy: 0.9054 - recall_8: 0.8886 - precision_8: 0.9215 - val_loss: 0.2193 - val_accuracy: 0.9254 - val_recall_8: 0.9139 - val_precision_8: 0.9347\n",
      "Epoch 145/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2660 - accuracy: 0.9060 - recall_8: 0.8915 - precision_8: 0.9223 - val_loss: 0.1936 - val_accuracy: 0.9324 - val_recall_8: 0.9231 - val_precision_8: 0.9457\n",
      "Epoch 146/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2702 - accuracy: 0.9039 - recall_8: 0.8877 - precision_8: 0.9200 - val_loss: 0.2057 - val_accuracy: 0.9254 - val_recall_8: 0.9185 - val_precision_8: 0.9336\n",
      "Epoch 147/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2641 - accuracy: 0.9045 - recall_8: 0.8896 - precision_8: 0.9211 - val_loss: 0.2052 - val_accuracy: 0.9239 - val_recall_8: 0.9178 - val_precision_8: 0.9328\n",
      "Epoch 148/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2603 - accuracy: 0.9069 - recall_8: 0.8928 - precision_8: 0.9218 - val_loss: 0.2080 - val_accuracy: 0.9262 - val_recall_8: 0.9178 - val_precision_8: 0.9379\n",
      "Epoch 149/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2691 - accuracy: 0.9026 - recall_8: 0.8884 - precision_8: 0.9189 - val_loss: 0.2111 - val_accuracy: 0.9293 - val_recall_8: 0.9178 - val_precision_8: 0.9402\n",
      "Epoch 150/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2696 - accuracy: 0.9035 - recall_8: 0.8877 - precision_8: 0.9202 - val_loss: 0.2081 - val_accuracy: 0.9293 - val_recall_8: 0.9170 - val_precision_8: 0.9431\n",
      "Epoch 151/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2660 - accuracy: 0.9050 - recall_8: 0.8909 - precision_8: 0.9208 - val_loss: 0.2000 - val_accuracy: 0.9301 - val_recall_8: 0.9185 - val_precision_8: 0.9439\n",
      "Epoch 152/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2657 - accuracy: 0.9044 - recall_8: 0.8889 - precision_8: 0.9214 - val_loss: 0.2085 - val_accuracy: 0.9224 - val_recall_8: 0.9078 - val_precision_8: 0.9343\n",
      "Epoch 153/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2694 - accuracy: 0.9038 - recall_8: 0.8904 - precision_8: 0.9193 - val_loss: 0.2126 - val_accuracy: 0.9293 - val_recall_8: 0.9139 - val_precision_8: 0.9377\n",
      "Epoch 154/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2594 - accuracy: 0.9061 - recall_8: 0.8917 - precision_8: 0.9228 - val_loss: 0.1993 - val_accuracy: 0.9316 - val_recall_8: 0.9216 - val_precision_8: 0.9419\n",
      "Epoch 155/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2646 - accuracy: 0.9061 - recall_8: 0.8921 - precision_8: 0.9211 - val_loss: 0.2008 - val_accuracy: 0.9293 - val_recall_8: 0.9193 - val_precision_8: 0.9432\n",
      "Epoch 156/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2623 - accuracy: 0.9050 - recall_8: 0.8910 - precision_8: 0.9211 - val_loss: 0.1959 - val_accuracy: 0.9339 - val_recall_8: 0.9239 - val_precision_8: 0.9405\n",
      "Epoch 157/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2598 - accuracy: 0.9056 - recall_8: 0.8916 - precision_8: 0.9204 - val_loss: 0.2030 - val_accuracy: 0.9262 - val_recall_8: 0.9170 - val_precision_8: 0.9409\n",
      "Epoch 158/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2614 - accuracy: 0.9056 - recall_8: 0.8914 - precision_8: 0.9198 - val_loss: 0.2092 - val_accuracy: 0.9216 - val_recall_8: 0.9047 - val_precision_8: 0.9386\n",
      "Epoch 159/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2640 - accuracy: 0.9064 - recall_8: 0.8918 - precision_8: 0.9211 - val_loss: 0.1951 - val_accuracy: 0.9347 - val_recall_8: 0.9285 - val_precision_8: 0.9445\n",
      "Epoch 160/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2622 - accuracy: 0.9047 - recall_8: 0.8907 - precision_8: 0.9207 - val_loss: 0.2021 - val_accuracy: 0.9270 - val_recall_8: 0.9193 - val_precision_8: 0.9380\n",
      "Epoch 161/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2537 - accuracy: 0.9077 - recall_8: 0.8931 - precision_8: 0.9233 - val_loss: 0.2069 - val_accuracy: 0.9216 - val_recall_8: 0.9162 - val_precision_8: 0.9320\n",
      "Epoch 162/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2625 - accuracy: 0.9077 - recall_8: 0.8931 - precision_8: 0.9215 - val_loss: 0.2019 - val_accuracy: 0.9331 - val_recall_8: 0.9239 - val_precision_8: 0.9487\n",
      "Epoch 163/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2569 - accuracy: 0.9070 - recall_8: 0.8928 - precision_8: 0.9221 - val_loss: 0.1978 - val_accuracy: 0.9331 - val_recall_8: 0.9254 - val_precision_8: 0.9451\n",
      "Epoch 164/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2579 - accuracy: 0.9069 - recall_8: 0.8931 - precision_8: 0.9222 - val_loss: 0.1974 - val_accuracy: 0.9362 - val_recall_8: 0.9293 - val_precision_8: 0.9475\n",
      "Epoch 165/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2563 - accuracy: 0.9099 - recall_8: 0.8966 - precision_8: 0.9249 - val_loss: 0.1981 - val_accuracy: 0.9316 - val_recall_8: 0.9277 - val_precision_8: 0.9408\n",
      "Epoch 166/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2562 - accuracy: 0.9084 - recall_8: 0.8946 - precision_8: 0.9234 - val_loss: 0.2065 - val_accuracy: 0.9270 - val_recall_8: 0.9185 - val_precision_8: 0.9365\n",
      "Epoch 167/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2538 - accuracy: 0.9081 - recall_8: 0.8944 - precision_8: 0.9225 - val_loss: 0.1920 - val_accuracy: 0.9339 - val_recall_8: 0.9239 - val_precision_8: 0.9435\n",
      "Epoch 168/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2602 - accuracy: 0.9060 - recall_8: 0.8923 - precision_8: 0.9213 - val_loss: 0.2105 - val_accuracy: 0.9277 - val_recall_8: 0.9178 - val_precision_8: 0.9379\n",
      "Epoch 169/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2523 - accuracy: 0.9096 - recall_8: 0.8970 - precision_8: 0.9243 - val_loss: 0.1988 - val_accuracy: 0.9324 - val_recall_8: 0.9247 - val_precision_8: 0.9421\n",
      "Epoch 170/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2575 - accuracy: 0.9065 - recall_8: 0.8932 - precision_8: 0.9213 - val_loss: 0.1967 - val_accuracy: 0.9308 - val_recall_8: 0.9231 - val_precision_8: 0.9420\n",
      "Epoch 171/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2613 - accuracy: 0.9074 - recall_8: 0.8931 - precision_8: 0.9229 - val_loss: 0.2036 - val_accuracy: 0.9285 - val_recall_8: 0.9224 - val_precision_8: 0.9419\n",
      "Epoch 172/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2616 - accuracy: 0.9065 - recall_8: 0.8926 - precision_8: 0.9225 - val_loss: 0.2043 - val_accuracy: 0.9247 - val_recall_8: 0.9162 - val_precision_8: 0.9356\n",
      "Epoch 173/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2479 - accuracy: 0.9104 - recall_8: 0.8971 - precision_8: 0.9260 - val_loss: 0.2071 - val_accuracy: 0.9247 - val_recall_8: 0.9185 - val_precision_8: 0.9358\n",
      "Epoch 174/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2556 - accuracy: 0.9098 - recall_8: 0.8960 - precision_8: 0.9241 - val_loss: 0.2023 - val_accuracy: 0.9285 - val_recall_8: 0.9193 - val_precision_8: 0.9388\n",
      "Epoch 175/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2519 - accuracy: 0.9098 - recall_8: 0.8951 - precision_8: 0.9251 - val_loss: 0.1946 - val_accuracy: 0.9254 - val_recall_8: 0.9193 - val_precision_8: 0.9395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2591 - accuracy: 0.9054 - recall_8: 0.8917 - precision_8: 0.9200 - val_loss: 0.1963 - val_accuracy: 0.9316 - val_recall_8: 0.9216 - val_precision_8: 0.9441\n",
      "Epoch 177/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2525 - accuracy: 0.9090 - recall_8: 0.8948 - precision_8: 0.9248 - val_loss: 0.1923 - val_accuracy: 0.9285 - val_recall_8: 0.9193 - val_precision_8: 0.9395\n",
      "Epoch 178/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2531 - accuracy: 0.9117 - recall_8: 0.8979 - precision_8: 0.9264 - val_loss: 0.2111 - val_accuracy: 0.9239 - val_recall_8: 0.9154 - val_precision_8: 0.9393\n",
      "Epoch 179/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2535 - accuracy: 0.9105 - recall_8: 0.8961 - precision_8: 0.9249 - val_loss: 0.2019 - val_accuracy: 0.9339 - val_recall_8: 0.9216 - val_precision_8: 0.9456\n",
      "Epoch 180/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2557 - accuracy: 0.9080 - recall_8: 0.8950 - precision_8: 0.9229 - val_loss: 0.1836 - val_accuracy: 0.9385 - val_recall_8: 0.9316 - val_precision_8: 0.9484\n",
      "Epoch 181/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2544 - accuracy: 0.9090 - recall_8: 0.8956 - precision_8: 0.9224 - val_loss: 0.2028 - val_accuracy: 0.9316 - val_recall_8: 0.9178 - val_precision_8: 0.9431\n",
      "Epoch 182/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2578 - accuracy: 0.9073 - recall_8: 0.8926 - precision_8: 0.9212 - val_loss: 0.2057 - val_accuracy: 0.9254 - val_recall_8: 0.9178 - val_precision_8: 0.9365\n",
      "Epoch 183/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2575 - accuracy: 0.9088 - recall_8: 0.8948 - precision_8: 0.9241 - val_loss: 0.2033 - val_accuracy: 0.9270 - val_recall_8: 0.9147 - val_precision_8: 0.9400\n",
      "Epoch 184/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2651 - accuracy: 0.9027 - recall_8: 0.8893 - precision_8: 0.9184 - val_loss: 0.1983 - val_accuracy: 0.9308 - val_recall_8: 0.9231 - val_precision_8: 0.9494\n",
      "Epoch 185/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2539 - accuracy: 0.9086 - recall_8: 0.8949 - precision_8: 0.9220 - val_loss: 0.1969 - val_accuracy: 0.9339 - val_recall_8: 0.9262 - val_precision_8: 0.9473\n",
      "Epoch 186/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2518 - accuracy: 0.9099 - recall_8: 0.8962 - precision_8: 0.9228 - val_loss: 0.1960 - val_accuracy: 0.9347 - val_recall_8: 0.9262 - val_precision_8: 0.9436\n",
      "Epoch 187/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2494 - accuracy: 0.9099 - recall_8: 0.8961 - precision_8: 0.9249 - val_loss: 0.1874 - val_accuracy: 0.9377 - val_recall_8: 0.9301 - val_precision_8: 0.9483\n",
      "Epoch 188/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2455 - accuracy: 0.9114 - recall_8: 0.8978 - precision_8: 0.9255 - val_loss: 0.1857 - val_accuracy: 0.9408 - val_recall_8: 0.9301 - val_precision_8: 0.9468\n",
      "Epoch 189/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2493 - accuracy: 0.9107 - recall_8: 0.8975 - precision_8: 0.9252 - val_loss: 0.1997 - val_accuracy: 0.9301 - val_recall_8: 0.9224 - val_precision_8: 0.9412\n",
      "Epoch 190/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2482 - accuracy: 0.9110 - recall_8: 0.8979 - precision_8: 0.9259 - val_loss: 0.1993 - val_accuracy: 0.9277 - val_recall_8: 0.9178 - val_precision_8: 0.9402\n",
      "Epoch 191/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2502 - accuracy: 0.9116 - recall_8: 0.8973 - precision_8: 0.9264 - val_loss: 0.1921 - val_accuracy: 0.9324 - val_recall_8: 0.9239 - val_precision_8: 0.9427\n",
      "Epoch 192/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2534 - accuracy: 0.9101 - recall_8: 0.8967 - precision_8: 0.9234 - val_loss: 0.1964 - val_accuracy: 0.9324 - val_recall_8: 0.9224 - val_precision_8: 0.9404\n",
      "Epoch 193/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2600 - accuracy: 0.9061 - recall_8: 0.8920 - precision_8: 0.9209 - val_loss: 0.1950 - val_accuracy: 0.9308 - val_recall_8: 0.9254 - val_precision_8: 0.9428\n",
      "Epoch 194/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2485 - accuracy: 0.9111 - recall_8: 0.8970 - precision_8: 0.9239 - val_loss: 0.1906 - val_accuracy: 0.9285 - val_recall_8: 0.9216 - val_precision_8: 0.9375\n",
      "Epoch 195/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2473 - accuracy: 0.9135 - recall_8: 0.9002 - precision_8: 0.9277 - val_loss: 0.1863 - val_accuracy: 0.9347 - val_recall_8: 0.9247 - val_precision_8: 0.9450\n",
      "Epoch 196/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2448 - accuracy: 0.9130 - recall_8: 0.9004 - precision_8: 0.9274 - val_loss: 0.1906 - val_accuracy: 0.9331 - val_recall_8: 0.9247 - val_precision_8: 0.9465\n",
      "Epoch 197/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2535 - accuracy: 0.9086 - recall_8: 0.8953 - precision_8: 0.9235 - val_loss: 0.2000 - val_accuracy: 0.9316 - val_recall_8: 0.9239 - val_precision_8: 0.9398\n",
      "Epoch 198/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2521 - accuracy: 0.9099 - recall_8: 0.8971 - precision_8: 0.9247 - val_loss: 0.1808 - val_accuracy: 0.9347 - val_recall_8: 0.9277 - val_precision_8: 0.9482\n",
      "Epoch 199/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2538 - accuracy: 0.9082 - recall_8: 0.8954 - precision_8: 0.9228 - val_loss: 0.1881 - val_accuracy: 0.9239 - val_recall_8: 0.9193 - val_precision_8: 0.9395\n",
      "Epoch 200/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2467 - accuracy: 0.9118 - recall_8: 0.8999 - precision_8: 0.9258 - val_loss: 0.1900 - val_accuracy: 0.9347 - val_recall_8: 0.9231 - val_precision_8: 0.9472\n",
      "Epoch 201/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2484 - accuracy: 0.9134 - recall_8: 0.8989 - precision_8: 0.9270 - val_loss: 0.1998 - val_accuracy: 0.9354 - val_recall_8: 0.9285 - val_precision_8: 0.9430\n",
      "Epoch 202/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2495 - accuracy: 0.9092 - recall_8: 0.8963 - precision_8: 0.9239 - val_loss: 0.1891 - val_accuracy: 0.9331 - val_recall_8: 0.9270 - val_precision_8: 0.9451\n",
      "Epoch 203/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2521 - accuracy: 0.9101 - recall_8: 0.8967 - precision_8: 0.9235 - val_loss: 0.1865 - val_accuracy: 0.9308 - val_recall_8: 0.9277 - val_precision_8: 0.9415\n",
      "Epoch 204/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2462 - accuracy: 0.9126 - recall_8: 0.8989 - precision_8: 0.9266 - val_loss: 0.2087 - val_accuracy: 0.9270 - val_recall_8: 0.9170 - val_precision_8: 0.9438\n",
      "Epoch 205/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2500 - accuracy: 0.9105 - recall_8: 0.8982 - precision_8: 0.9251 - val_loss: 0.2020 - val_accuracy: 0.9277 - val_recall_8: 0.9201 - val_precision_8: 0.9448\n",
      "Epoch 206/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2491 - accuracy: 0.9115 - recall_8: 0.8980 - precision_8: 0.9242 - val_loss: 0.2037 - val_accuracy: 0.9277 - val_recall_8: 0.9193 - val_precision_8: 0.9395\n",
      "Epoch 207/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2479 - accuracy: 0.9103 - recall_8: 0.8988 - precision_8: 0.9236 - val_loss: 0.1937 - val_accuracy: 0.9324 - val_recall_8: 0.9247 - val_precision_8: 0.9421\n",
      "Epoch 208/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2409 - accuracy: 0.9136 - recall_8: 0.9007 - precision_8: 0.9281 - val_loss: 0.1987 - val_accuracy: 0.9277 - val_recall_8: 0.9208 - val_precision_8: 0.9381\n",
      "Epoch 209/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2441 - accuracy: 0.9107 - recall_8: 0.8984 - precision_8: 0.9252 - val_loss: 0.2072 - val_accuracy: 0.9239 - val_recall_8: 0.9147 - val_precision_8: 0.9348\n",
      "Epoch 210/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2486 - accuracy: 0.9120 - recall_8: 0.8989 - precision_8: 0.9256 - val_loss: 0.1878 - val_accuracy: 0.9362 - val_recall_8: 0.9270 - val_precision_8: 0.9444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2458 - accuracy: 0.9139 - recall_8: 0.9003 - precision_8: 0.9263 - val_loss: 0.1894 - val_accuracy: 0.9331 - val_recall_8: 0.9224 - val_precision_8: 0.9456\n",
      "Epoch 212/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2468 - accuracy: 0.9108 - recall_8: 0.8990 - precision_8: 0.9251 - val_loss: 0.1865 - val_accuracy: 0.9393 - val_recall_8: 0.9347 - val_precision_8: 0.9500\n",
      "Epoch 213/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2489 - accuracy: 0.9111 - recall_8: 0.8991 - precision_8: 0.9249 - val_loss: 0.1923 - val_accuracy: 0.9301 - val_recall_8: 0.9231 - val_precision_8: 0.9405\n",
      "Epoch 214/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2439 - accuracy: 0.9141 - recall_8: 0.9016 - precision_8: 0.9283 - val_loss: 0.2036 - val_accuracy: 0.9254 - val_recall_8: 0.9139 - val_precision_8: 0.9422\n",
      "Epoch 215/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2452 - accuracy: 0.9109 - recall_8: 0.8984 - precision_8: 0.9254 - val_loss: 0.1827 - val_accuracy: 0.9370 - val_recall_8: 0.9301 - val_precision_8: 0.9483\n",
      "Epoch 216/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2397 - accuracy: 0.9144 - recall_8: 0.9024 - precision_8: 0.9284 - val_loss: 0.1817 - val_accuracy: 0.9324 - val_recall_8: 0.9293 - val_precision_8: 0.9468\n",
      "Epoch 217/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2458 - accuracy: 0.9130 - recall_8: 0.9014 - precision_8: 0.9248 - val_loss: 0.1912 - val_accuracy: 0.9362 - val_recall_8: 0.9301 - val_precision_8: 0.9461\n",
      "Epoch 218/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2430 - accuracy: 0.9118 - recall_8: 0.8992 - precision_8: 0.9265 - val_loss: 0.1942 - val_accuracy: 0.9308 - val_recall_8: 0.9224 - val_precision_8: 0.9419\n",
      "Epoch 219/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2444 - accuracy: 0.9118 - recall_8: 0.8994 - precision_8: 0.9255 - val_loss: 0.1921 - val_accuracy: 0.9347 - val_recall_8: 0.9301 - val_precision_8: 0.9461\n",
      "Epoch 220/2500\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2444 - accuracy: 0.9129 - recall_8: 0.8994 - precision_8: 0.9272 - val_loss: 0.1868 - val_accuracy: 0.9377 - val_recall_8: 0.9270 - val_precision_8: 0.9496\n",
      "Epoch 221/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2485 - accuracy: 0.9096 - recall_8: 0.8961 - precision_8: 0.9235 - val_loss: 0.1909 - val_accuracy: 0.9354 - val_recall_8: 0.9247 - val_precision_8: 0.9428\n",
      "Epoch 222/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2439 - accuracy: 0.9130 - recall_8: 0.9002 - precision_8: 0.9265 - val_loss: 0.1900 - val_accuracy: 0.9270 - val_recall_8: 0.9154 - val_precision_8: 0.9415\n",
      "Epoch 223/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2460 - accuracy: 0.9131 - recall_8: 0.9006 - precision_8: 0.9268 - val_loss: 0.1837 - val_accuracy: 0.9324 - val_recall_8: 0.9247 - val_precision_8: 0.9443\n",
      "Epoch 224/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2394 - accuracy: 0.9133 - recall_8: 0.9013 - precision_8: 0.9275 - val_loss: 0.1868 - val_accuracy: 0.9347 - val_recall_8: 0.9262 - val_precision_8: 0.9458\n",
      "Epoch 225/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2372 - accuracy: 0.9150 - recall_8: 0.9038 - precision_8: 0.9286 - val_loss: 0.1984 - val_accuracy: 0.9308 - val_recall_8: 0.9216 - val_precision_8: 0.9448\n",
      "Epoch 226/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2492 - accuracy: 0.9101 - recall_8: 0.8989 - precision_8: 0.9246 - val_loss: 0.1827 - val_accuracy: 0.9347 - val_recall_8: 0.9301 - val_precision_8: 0.9438\n",
      "Epoch 227/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2463 - accuracy: 0.9126 - recall_8: 0.9002 - precision_8: 0.9268 - val_loss: 0.1888 - val_accuracy: 0.9339 - val_recall_8: 0.9293 - val_precision_8: 0.9460\n",
      "Epoch 228/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2342 - accuracy: 0.9167 - recall_8: 0.9047 - precision_8: 0.9301 - val_loss: 0.1911 - val_accuracy: 0.9293 - val_recall_8: 0.9216 - val_precision_8: 0.9448\n",
      "Epoch 229/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2400 - accuracy: 0.9146 - recall_8: 0.9024 - precision_8: 0.9286 - val_loss: 0.1868 - val_accuracy: 0.9324 - val_recall_8: 0.9239 - val_precision_8: 0.9457\n",
      "Epoch 230/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2419 - accuracy: 0.9146 - recall_8: 0.9031 - precision_8: 0.9278 - val_loss: 0.1863 - val_accuracy: 0.9393 - val_recall_8: 0.9270 - val_precision_8: 0.9466\n",
      "Epoch 231/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2380 - accuracy: 0.9156 - recall_8: 0.9038 - precision_8: 0.9276 - val_loss: 0.1877 - val_accuracy: 0.9262 - val_recall_8: 0.9224 - val_precision_8: 0.9404\n",
      "Epoch 232/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2392 - accuracy: 0.9146 - recall_8: 0.9016 - precision_8: 0.9274 - val_loss: 0.1827 - val_accuracy: 0.9370 - val_recall_8: 0.9324 - val_precision_8: 0.9462\n",
      "Epoch 233/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2411 - accuracy: 0.9123 - recall_8: 0.9008 - precision_8: 0.9257 - val_loss: 0.1896 - val_accuracy: 0.9324 - val_recall_8: 0.9254 - val_precision_8: 0.9443\n",
      "Epoch 234/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2389 - accuracy: 0.9154 - recall_8: 0.9027 - precision_8: 0.9289 - val_loss: 0.1764 - val_accuracy: 0.9454 - val_recall_8: 0.9370 - val_precision_8: 0.9538\n",
      "Epoch 235/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2449 - accuracy: 0.9133 - recall_8: 0.9005 - precision_8: 0.9272 - val_loss: 0.1909 - val_accuracy: 0.9339 - val_recall_8: 0.9254 - val_precision_8: 0.9465\n",
      "Epoch 236/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2374 - accuracy: 0.9142 - recall_8: 0.9025 - precision_8: 0.9274 - val_loss: 0.1962 - val_accuracy: 0.9293 - val_recall_8: 0.9254 - val_precision_8: 0.9399\n",
      "Epoch 237/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2516 - accuracy: 0.9078 - recall_8: 0.8961 - precision_8: 0.9222 - val_loss: 0.1864 - val_accuracy: 0.9339 - val_recall_8: 0.9231 - val_precision_8: 0.9405\n",
      "Epoch 238/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2464 - accuracy: 0.9127 - recall_8: 0.9011 - precision_8: 0.9262 - val_loss: 0.1864 - val_accuracy: 0.9385 - val_recall_8: 0.9324 - val_precision_8: 0.9491\n",
      "Epoch 239/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2427 - accuracy: 0.9129 - recall_8: 0.9000 - precision_8: 0.9268 - val_loss: 0.1911 - val_accuracy: 0.9354 - val_recall_8: 0.9216 - val_precision_8: 0.9448\n",
      "Epoch 240/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2401 - accuracy: 0.9143 - recall_8: 0.9020 - precision_8: 0.9284 - val_loss: 0.1910 - val_accuracy: 0.9339 - val_recall_8: 0.9293 - val_precision_8: 0.9460\n",
      "Epoch 241/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2325 - accuracy: 0.9171 - recall_8: 0.9052 - precision_8: 0.9307 - val_loss: 0.1853 - val_accuracy: 0.9339 - val_recall_8: 0.9293 - val_precision_8: 0.9453\n",
      "Epoch 242/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2357 - accuracy: 0.9173 - recall_8: 0.9053 - precision_8: 0.9306 - val_loss: 0.1816 - val_accuracy: 0.9362 - val_recall_8: 0.9301 - val_precision_8: 0.9461\n",
      "Epoch 243/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2348 - accuracy: 0.9164 - recall_8: 0.9044 - precision_8: 0.9294 - val_loss: 0.1746 - val_accuracy: 0.9424 - val_recall_8: 0.9347 - val_precision_8: 0.9500\n",
      "Epoch 244/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2365 - accuracy: 0.9149 - recall_8: 0.9030 - precision_8: 0.9279 - val_loss: 0.1723 - val_accuracy: 0.9393 - val_recall_8: 0.9331 - val_precision_8: 0.9514\n",
      "Epoch 245/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2381 - accuracy: 0.9142 - recall_8: 0.9023 - precision_8: 0.9278 - val_loss: 0.1813 - val_accuracy: 0.9408 - val_recall_8: 0.9301 - val_precision_8: 0.9490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2381 - accuracy: 0.9137 - recall_8: 0.9020 - precision_8: 0.9276 - val_loss: 0.1889 - val_accuracy: 0.9385 - val_recall_8: 0.9301 - val_precision_8: 0.9513\n",
      "Epoch 247/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2384 - accuracy: 0.9139 - recall_8: 0.9033 - precision_8: 0.9261 - val_loss: 0.1969 - val_accuracy: 0.9270 - val_recall_8: 0.9216 - val_precision_8: 0.9441\n",
      "Epoch 248/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2411 - accuracy: 0.9131 - recall_8: 0.9005 - precision_8: 0.9277 - val_loss: 0.1847 - val_accuracy: 0.9362 - val_recall_8: 0.9277 - val_precision_8: 0.9444\n",
      "Epoch 249/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2434 - accuracy: 0.9126 - recall_8: 0.8997 - precision_8: 0.9249 - val_loss: 0.1832 - val_accuracy: 0.9408 - val_recall_8: 0.9331 - val_precision_8: 0.9514\n",
      "Epoch 250/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2409 - accuracy: 0.9137 - recall_8: 0.9011 - precision_8: 0.9251 - val_loss: 0.1830 - val_accuracy: 0.9370 - val_recall_8: 0.9331 - val_precision_8: 0.9462\n",
      "Epoch 251/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2384 - accuracy: 0.9148 - recall_8: 0.9026 - precision_8: 0.9280 - val_loss: 0.1876 - val_accuracy: 0.9385 - val_recall_8: 0.9316 - val_precision_8: 0.9439\n",
      "Epoch 252/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2312 - accuracy: 0.9159 - recall_8: 0.9050 - precision_8: 0.9285 - val_loss: 0.1785 - val_accuracy: 0.9347 - val_recall_8: 0.9316 - val_precision_8: 0.9454\n",
      "Epoch 253/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2359 - accuracy: 0.9145 - recall_8: 0.9028 - precision_8: 0.9275 - val_loss: 0.1776 - val_accuracy: 0.9431 - val_recall_8: 0.9385 - val_precision_8: 0.9524\n",
      "Epoch 254/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2413 - accuracy: 0.9145 - recall_8: 0.9031 - precision_8: 0.9274 - val_loss: 0.1806 - val_accuracy: 0.9424 - val_recall_8: 0.9331 - val_precision_8: 0.9537\n",
      "Epoch 255/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2296 - accuracy: 0.9187 - recall_8: 0.9060 - precision_8: 0.9313 - val_loss: 0.1718 - val_accuracy: 0.9400 - val_recall_8: 0.9331 - val_precision_8: 0.9537\n",
      "Epoch 256/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2336 - accuracy: 0.9162 - recall_8: 0.9041 - precision_8: 0.9300 - val_loss: 0.1823 - val_accuracy: 0.9408 - val_recall_8: 0.9262 - val_precision_8: 0.9526\n",
      "Epoch 257/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2317 - accuracy: 0.9157 - recall_8: 0.9033 - precision_8: 0.9286 - val_loss: 0.1862 - val_accuracy: 0.9416 - val_recall_8: 0.9277 - val_precision_8: 0.9496\n",
      "Epoch 258/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2357 - accuracy: 0.9147 - recall_8: 0.9024 - precision_8: 0.9254 - val_loss: 0.1776 - val_accuracy: 0.9416 - val_recall_8: 0.9347 - val_precision_8: 0.9507\n",
      "Epoch 259/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2363 - accuracy: 0.9158 - recall_8: 0.9039 - precision_8: 0.9282 - val_loss: 0.1866 - val_accuracy: 0.9331 - val_recall_8: 0.9308 - val_precision_8: 0.9498\n",
      "Epoch 260/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2404 - accuracy: 0.9130 - recall_8: 0.9019 - precision_8: 0.9258 - val_loss: 0.1915 - val_accuracy: 0.9331 - val_recall_8: 0.9262 - val_precision_8: 0.9444\n",
      "Epoch 261/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2376 - accuracy: 0.9158 - recall_8: 0.9043 - precision_8: 0.9292 - val_loss: 0.1775 - val_accuracy: 0.9370 - val_recall_8: 0.9293 - val_precision_8: 0.9468\n",
      "Epoch 262/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2345 - accuracy: 0.9156 - recall_8: 0.9028 - precision_8: 0.9281 - val_loss: 0.1780 - val_accuracy: 0.9439 - val_recall_8: 0.9362 - val_precision_8: 0.9523\n",
      "Epoch 263/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2405 - accuracy: 0.9143 - recall_8: 0.9016 - precision_8: 0.9267 - val_loss: 0.1834 - val_accuracy: 0.9324 - val_recall_8: 0.9254 - val_precision_8: 0.9428\n",
      "Epoch 264/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2352 - accuracy: 0.9174 - recall_8: 0.9060 - precision_8: 0.9292 - val_loss: 0.1769 - val_accuracy: 0.9447 - val_recall_8: 0.9400 - val_precision_8: 0.9495\n",
      "Epoch 265/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2346 - accuracy: 0.9173 - recall_8: 0.9039 - precision_8: 0.9299 - val_loss: 0.1819 - val_accuracy: 0.9385 - val_recall_8: 0.9331 - val_precision_8: 0.9492\n",
      "Epoch 266/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2353 - accuracy: 0.9152 - recall_8: 0.9038 - precision_8: 0.9283 - val_loss: 0.1799 - val_accuracy: 0.9377 - val_recall_8: 0.9324 - val_precision_8: 0.9506\n",
      "Epoch 267/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2295 - accuracy: 0.9188 - recall_8: 0.9073 - precision_8: 0.9301 - val_loss: 0.1849 - val_accuracy: 0.9385 - val_recall_8: 0.9308 - val_precision_8: 0.9498\n",
      "Epoch 268/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2364 - accuracy: 0.9143 - recall_8: 0.9029 - precision_8: 0.9264 - val_loss: 0.1854 - val_accuracy: 0.9362 - val_recall_8: 0.9316 - val_precision_8: 0.9491\n",
      "Epoch 269/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2309 - accuracy: 0.9171 - recall_8: 0.9056 - precision_8: 0.9297 - val_loss: 0.1883 - val_accuracy: 0.9362 - val_recall_8: 0.9324 - val_precision_8: 0.9484\n",
      "Epoch 270/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2314 - accuracy: 0.9169 - recall_8: 0.9048 - precision_8: 0.9295 - val_loss: 0.1808 - val_accuracy: 0.9370 - val_recall_8: 0.9293 - val_precision_8: 0.9460\n",
      "Epoch 271/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2309 - accuracy: 0.9175 - recall_8: 0.9062 - precision_8: 0.9299 - val_loss: 0.1842 - val_accuracy: 0.9362 - val_recall_8: 0.9285 - val_precision_8: 0.9482\n",
      "Epoch 272/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2371 - accuracy: 0.9158 - recall_8: 0.9041 - precision_8: 0.9284 - val_loss: 0.1898 - val_accuracy: 0.9370 - val_recall_8: 0.9308 - val_precision_8: 0.9505\n",
      "Epoch 273/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2419 - accuracy: 0.9128 - recall_8: 0.9007 - precision_8: 0.9262 - val_loss: 0.1840 - val_accuracy: 0.9362 - val_recall_8: 0.9293 - val_precision_8: 0.9482\n",
      "Epoch 274/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2303 - accuracy: 0.9178 - recall_8: 0.9066 - precision_8: 0.9306 - val_loss: 0.1718 - val_accuracy: 0.9439 - val_recall_8: 0.9393 - val_precision_8: 0.9532\n",
      "Epoch 275/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2286 - accuracy: 0.9167 - recall_8: 0.9063 - precision_8: 0.9286 - val_loss: 0.1768 - val_accuracy: 0.9454 - val_recall_8: 0.9362 - val_precision_8: 0.9568\n",
      "Epoch 276/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2334 - accuracy: 0.9179 - recall_8: 0.9064 - precision_8: 0.9306 - val_loss: 0.1882 - val_accuracy: 0.9416 - val_recall_8: 0.9316 - val_precision_8: 0.9469\n",
      "Epoch 277/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2334 - accuracy: 0.9149 - recall_8: 0.9041 - precision_8: 0.9274 - val_loss: 0.1724 - val_accuracy: 0.9447 - val_recall_8: 0.9316 - val_precision_8: 0.9551\n",
      "Epoch 278/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2347 - accuracy: 0.9147 - recall_8: 0.9033 - precision_8: 0.9292 - val_loss: 0.1841 - val_accuracy: 0.9370 - val_recall_8: 0.9208 - val_precision_8: 0.9478\n",
      "Epoch 279/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2259 - accuracy: 0.9202 - recall_8: 0.9096 - precision_8: 0.9321 - val_loss: 0.1748 - val_accuracy: 0.9408 - val_recall_8: 0.9331 - val_precision_8: 0.9514\n",
      "Epoch 280/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2316 - accuracy: 0.9173 - recall_8: 0.9061 - precision_8: 0.9297 - val_loss: 0.1868 - val_accuracy: 0.9339 - val_recall_8: 0.9293 - val_precision_8: 0.9460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2351 - accuracy: 0.9173 - recall_8: 0.9057 - precision_8: 0.9295 - val_loss: 0.1825 - val_accuracy: 0.9370 - val_recall_8: 0.9277 - val_precision_8: 0.9489\n",
      "Epoch 282/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2395 - accuracy: 0.9151 - recall_8: 0.9031 - precision_8: 0.9276 - val_loss: 0.1877 - val_accuracy: 0.9316 - val_recall_8: 0.9262 - val_precision_8: 0.9473\n",
      "Epoch 283/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2245 - accuracy: 0.9195 - recall_8: 0.9071 - precision_8: 0.9308 - val_loss: 0.1903 - val_accuracy: 0.9277 - val_recall_8: 0.9216 - val_precision_8: 0.9389\n",
      "Epoch 284/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2298 - accuracy: 0.9188 - recall_8: 0.9071 - precision_8: 0.9317 - val_loss: 0.1776 - val_accuracy: 0.9377 - val_recall_8: 0.9293 - val_precision_8: 0.9512\n",
      "Epoch 285/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2288 - accuracy: 0.9179 - recall_8: 0.9062 - precision_8: 0.9304 - val_loss: 0.1748 - val_accuracy: 0.9362 - val_recall_8: 0.9308 - val_precision_8: 0.9439\n",
      "Epoch 286/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2313 - accuracy: 0.9166 - recall_8: 0.9068 - precision_8: 0.9290 - val_loss: 0.1818 - val_accuracy: 0.9370 - val_recall_8: 0.9308 - val_precision_8: 0.9513\n",
      "Epoch 287/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2249 - accuracy: 0.9192 - recall_8: 0.9096 - precision_8: 0.9311 - val_loss: 0.1755 - val_accuracy: 0.9393 - val_recall_8: 0.9339 - val_precision_8: 0.9500\n",
      "Epoch 288/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2329 - accuracy: 0.9186 - recall_8: 0.9078 - precision_8: 0.9297 - val_loss: 0.1770 - val_accuracy: 0.9354 - val_recall_8: 0.9301 - val_precision_8: 0.9446\n",
      "Epoch 289/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2262 - accuracy: 0.9202 - recall_8: 0.9092 - precision_8: 0.9319 - val_loss: 0.1776 - val_accuracy: 0.9370 - val_recall_8: 0.9308 - val_precision_8: 0.9498\n",
      "Epoch 290/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2282 - accuracy: 0.9181 - recall_8: 0.9090 - precision_8: 0.9308 - val_loss: 0.1834 - val_accuracy: 0.9354 - val_recall_8: 0.9301 - val_precision_8: 0.9453\n",
      "Epoch 291/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2246 - accuracy: 0.9191 - recall_8: 0.9077 - precision_8: 0.9300 - val_loss: 0.1790 - val_accuracy: 0.9385 - val_recall_8: 0.9316 - val_precision_8: 0.9498\n",
      "Epoch 292/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2277 - accuracy: 0.9178 - recall_8: 0.9070 - precision_8: 0.9288 - val_loss: 0.1765 - val_accuracy: 0.9408 - val_recall_8: 0.9316 - val_precision_8: 0.9543\n",
      "Epoch 293/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2283 - accuracy: 0.9176 - recall_8: 0.9063 - precision_8: 0.9299 - val_loss: 0.1749 - val_accuracy: 0.9424 - val_recall_8: 0.9324 - val_precision_8: 0.9499\n",
      "Epoch 294/2500\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2298 - accuracy: 0.9178 - recall_8: 0.9080 - precision_8: 0.9303 - val_loss: 0.1829 - val_accuracy: 0.9393 - val_recall_8: 0.9339 - val_precision_8: 0.9537\n",
      "Epoch 295/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2316 - accuracy: 0.9180 - recall_8: 0.9072 - precision_8: 0.9307 - val_loss: 0.1827 - val_accuracy: 0.9362 - val_recall_8: 0.9301 - val_precision_8: 0.9453\n",
      "Epoch 296/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2289 - accuracy: 0.9176 - recall_8: 0.9068 - precision_8: 0.9303 - val_loss: 0.1772 - val_accuracy: 0.9447 - val_recall_8: 0.9362 - val_precision_8: 0.9516\n",
      "Epoch 297/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2298 - accuracy: 0.9178 - recall_8: 0.9075 - precision_8: 0.9291 - val_loss: 0.1885 - val_accuracy: 0.9400 - val_recall_8: 0.9285 - val_precision_8: 0.9519\n",
      "Epoch 298/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2257 - accuracy: 0.9207 - recall_8: 0.9105 - precision_8: 0.9314 - val_loss: 0.1765 - val_accuracy: 0.9393 - val_recall_8: 0.9293 - val_precision_8: 0.9490\n",
      "Epoch 299/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2337 - accuracy: 0.9171 - recall_8: 0.9058 - precision_8: 0.9288 - val_loss: 0.1805 - val_accuracy: 0.9393 - val_recall_8: 0.9301 - val_precision_8: 0.9475\n",
      "Epoch 300/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2287 - accuracy: 0.9187 - recall_8: 0.9080 - precision_8: 0.9299 - val_loss: 0.1957 - val_accuracy: 0.9339 - val_recall_8: 0.9285 - val_precision_8: 0.9489\n",
      "Epoch 301/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2342 - accuracy: 0.9157 - recall_8: 0.9038 - precision_8: 0.9279 - val_loss: 0.1834 - val_accuracy: 0.9385 - val_recall_8: 0.9339 - val_precision_8: 0.9448\n",
      "Epoch 302/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2212 - accuracy: 0.9218 - recall_8: 0.9105 - precision_8: 0.9331 - val_loss: 0.1808 - val_accuracy: 0.9416 - val_recall_8: 0.9362 - val_precision_8: 0.9479\n",
      "Epoch 303/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2294 - accuracy: 0.9185 - recall_8: 0.9077 - precision_8: 0.9311 - val_loss: 0.1746 - val_accuracy: 0.9408 - val_recall_8: 0.9324 - val_precision_8: 0.9506\n",
      "Epoch 304/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2250 - accuracy: 0.9182 - recall_8: 0.9073 - precision_8: 0.9303 - val_loss: 0.1641 - val_accuracy: 0.9454 - val_recall_8: 0.9393 - val_precision_8: 0.9577\n",
      "Epoch 305/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2253 - accuracy: 0.9216 - recall_8: 0.9106 - precision_8: 0.9321 - val_loss: 0.1779 - val_accuracy: 0.9393 - val_recall_8: 0.9316 - val_precision_8: 0.9498\n",
      "Epoch 306/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2318 - accuracy: 0.9186 - recall_8: 0.9077 - precision_8: 0.9306 - val_loss: 0.1887 - val_accuracy: 0.9385 - val_recall_8: 0.9331 - val_precision_8: 0.9492\n",
      "Epoch 307/2500\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2278 - accuracy: 0.9180 - recall_8: 0.9065 - precision_8: 0.9311 - val_loss: 0.1813 - val_accuracy: 0.9400 - val_recall_8: 0.9347 - val_precision_8: 0.9530\n",
      "Epoch 308/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2250 - accuracy: 0.9198 - recall_8: 0.9080 - precision_8: 0.9324 - val_loss: 0.1878 - val_accuracy: 0.9377 - val_recall_8: 0.9308 - val_precision_8: 0.9505\n",
      "Epoch 309/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2254 - accuracy: 0.9201 - recall_8: 0.9095 - precision_8: 0.9314 - val_loss: 0.1779 - val_accuracy: 0.9408 - val_recall_8: 0.9362 - val_precision_8: 0.9538\n",
      "Epoch 310/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2248 - accuracy: 0.9199 - recall_8: 0.9092 - precision_8: 0.9322 - val_loss: 0.1860 - val_accuracy: 0.9400 - val_recall_8: 0.9324 - val_precision_8: 0.9484\n",
      "Epoch 311/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2237 - accuracy: 0.9201 - recall_8: 0.9096 - precision_8: 0.9319 - val_loss: 0.1866 - val_accuracy: 0.9331 - val_recall_8: 0.9277 - val_precision_8: 0.9430\n",
      "Epoch 312/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2245 - accuracy: 0.9197 - recall_8: 0.9090 - precision_8: 0.9321 - val_loss: 0.1833 - val_accuracy: 0.9377 - val_recall_8: 0.9308 - val_precision_8: 0.9528\n",
      "Epoch 313/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2258 - accuracy: 0.9199 - recall_8: 0.9100 - precision_8: 0.9318 - val_loss: 0.1832 - val_accuracy: 0.9408 - val_recall_8: 0.9331 - val_precision_8: 0.9507\n",
      "Epoch 314/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2262 - accuracy: 0.9181 - recall_8: 0.9080 - precision_8: 0.9314 - val_loss: 0.1886 - val_accuracy: 0.9408 - val_recall_8: 0.9354 - val_precision_8: 0.9530\n",
      "Epoch 315/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2223 - accuracy: 0.9204 - recall_8: 0.9098 - precision_8: 0.9305 - val_loss: 0.1815 - val_accuracy: 0.9470 - val_recall_8: 0.9393 - val_precision_8: 0.9547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 316/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2296 - accuracy: 0.9170 - recall_8: 0.9061 - precision_8: 0.9297 - val_loss: 0.1758 - val_accuracy: 0.9439 - val_recall_8: 0.9377 - val_precision_8: 0.9524\n",
      "Epoch 317/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2224 - accuracy: 0.9186 - recall_8: 0.9073 - precision_8: 0.9311 - val_loss: 0.1793 - val_accuracy: 0.9439 - val_recall_8: 0.9362 - val_precision_8: 0.9508\n",
      "Epoch 318/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2294 - accuracy: 0.9183 - recall_8: 0.9073 - precision_8: 0.9305 - val_loss: 0.1898 - val_accuracy: 0.9362 - val_recall_8: 0.9285 - val_precision_8: 0.9519\n",
      "Epoch 319/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2244 - accuracy: 0.9194 - recall_8: 0.9094 - precision_8: 0.9306 - val_loss: 0.1858 - val_accuracy: 0.9393 - val_recall_8: 0.9262 - val_precision_8: 0.9488\n",
      "Epoch 320/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2285 - accuracy: 0.9194 - recall_8: 0.9088 - precision_8: 0.9303 - val_loss: 0.1822 - val_accuracy: 0.9362 - val_recall_8: 0.9277 - val_precision_8: 0.9519\n",
      "Epoch 321/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2252 - accuracy: 0.9192 - recall_8: 0.9086 - precision_8: 0.9306 - val_loss: 0.1694 - val_accuracy: 0.9439 - val_recall_8: 0.9377 - val_precision_8: 0.9509\n",
      "Epoch 322/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2205 - accuracy: 0.9210 - recall_8: 0.9116 - precision_8: 0.9321 - val_loss: 0.1685 - val_accuracy: 0.9447 - val_recall_8: 0.9385 - val_precision_8: 0.9561\n",
      "Epoch 323/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2235 - accuracy: 0.9199 - recall_8: 0.9088 - precision_8: 0.9313 - val_loss: 0.1776 - val_accuracy: 0.9377 - val_recall_8: 0.9339 - val_precision_8: 0.9441\n",
      "Epoch 324/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2244 - accuracy: 0.9199 - recall_8: 0.9086 - precision_8: 0.9310 - val_loss: 0.1880 - val_accuracy: 0.9347 - val_recall_8: 0.9293 - val_precision_8: 0.9475\n",
      "Epoch 325/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2254 - accuracy: 0.9194 - recall_8: 0.9098 - precision_8: 0.9314 - val_loss: 0.1702 - val_accuracy: 0.9408 - val_recall_8: 0.9339 - val_precision_8: 0.9500\n",
      "Epoch 326/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2332 - accuracy: 0.9182 - recall_8: 0.9077 - precision_8: 0.9294 - val_loss: 0.1785 - val_accuracy: 0.9400 - val_recall_8: 0.9308 - val_precision_8: 0.9483\n",
      "Epoch 327/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2248 - accuracy: 0.9197 - recall_8: 0.9098 - precision_8: 0.9325 - val_loss: 0.1788 - val_accuracy: 0.9331 - val_recall_8: 0.9262 - val_precision_8: 0.9458\n",
      "Epoch 328/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2306 - accuracy: 0.9163 - recall_8: 0.9058 - precision_8: 0.9285 - val_loss: 0.1797 - val_accuracy: 0.9408 - val_recall_8: 0.9331 - val_precision_8: 0.9507\n",
      "Epoch 329/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2239 - accuracy: 0.9213 - recall_8: 0.9103 - precision_8: 0.9324 - val_loss: 0.1788 - val_accuracy: 0.9385 - val_recall_8: 0.9324 - val_precision_8: 0.9462\n",
      "Epoch 330/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2281 - accuracy: 0.9193 - recall_8: 0.9077 - precision_8: 0.9307 - val_loss: 0.1818 - val_accuracy: 0.9416 - val_recall_8: 0.9308 - val_precision_8: 0.9491\n",
      "Epoch 331/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2199 - accuracy: 0.9211 - recall_8: 0.9110 - precision_8: 0.9324 - val_loss: 0.1792 - val_accuracy: 0.9377 - val_recall_8: 0.9316 - val_precision_8: 0.9476\n",
      "Epoch 332/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2180 - accuracy: 0.9222 - recall_8: 0.9122 - precision_8: 0.9339 - val_loss: 0.1661 - val_accuracy: 0.9439 - val_recall_8: 0.9370 - val_precision_8: 0.9538\n",
      "Epoch 333/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2176 - accuracy: 0.9233 - recall_8: 0.9128 - precision_8: 0.9342 - val_loss: 0.1737 - val_accuracy: 0.9393 - val_recall_8: 0.9308 - val_precision_8: 0.9566\n",
      "Epoch 334/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2249 - accuracy: 0.9193 - recall_8: 0.9088 - precision_8: 0.9303 - val_loss: 0.1867 - val_accuracy: 0.9331 - val_recall_8: 0.9270 - val_precision_8: 0.9466\n",
      "Epoch 335/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2216 - accuracy: 0.9198 - recall_8: 0.9084 - precision_8: 0.9315 - val_loss: 0.1901 - val_accuracy: 0.9385 - val_recall_8: 0.9285 - val_precision_8: 0.9438\n",
      "Epoch 336/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2273 - accuracy: 0.9198 - recall_8: 0.9105 - precision_8: 0.9316 - val_loss: 0.1866 - val_accuracy: 0.9377 - val_recall_8: 0.9277 - val_precision_8: 0.9489\n",
      "Epoch 337/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2278 - accuracy: 0.9182 - recall_8: 0.9076 - precision_8: 0.9297 - val_loss: 0.1760 - val_accuracy: 0.9424 - val_recall_8: 0.9377 - val_precision_8: 0.9554\n",
      "Epoch 338/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2191 - accuracy: 0.9211 - recall_8: 0.9105 - precision_8: 0.9323 - val_loss: 0.1859 - val_accuracy: 0.9431 - val_recall_8: 0.9347 - val_precision_8: 0.9456\n",
      "Epoch 339/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2289 - accuracy: 0.9178 - recall_8: 0.9089 - precision_8: 0.9299 - val_loss: 0.1739 - val_accuracy: 0.9400 - val_recall_8: 0.9354 - val_precision_8: 0.9560\n",
      "Epoch 340/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2216 - accuracy: 0.9215 - recall_8: 0.9119 - precision_8: 0.9320 - val_loss: 0.1704 - val_accuracy: 0.9416 - val_recall_8: 0.9324 - val_precision_8: 0.9521\n",
      "Epoch 341/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2215 - accuracy: 0.9206 - recall_8: 0.9107 - precision_8: 0.9318 - val_loss: 0.1649 - val_accuracy: 0.9462 - val_recall_8: 0.9385 - val_precision_8: 0.9569\n",
      "Epoch 342/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2189 - accuracy: 0.9216 - recall_8: 0.9113 - precision_8: 0.9331 - val_loss: 0.1693 - val_accuracy: 0.9416 - val_recall_8: 0.9331 - val_precision_8: 0.9507\n",
      "Epoch 343/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2222 - accuracy: 0.9210 - recall_8: 0.9105 - precision_8: 0.9331 - val_loss: 0.1799 - val_accuracy: 0.9400 - val_recall_8: 0.9339 - val_precision_8: 0.9492\n",
      "Epoch 344/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2196 - accuracy: 0.9200 - recall_8: 0.9093 - precision_8: 0.9300 - val_loss: 0.1757 - val_accuracy: 0.9377 - val_recall_8: 0.9347 - val_precision_8: 0.9463\n",
      "Epoch 345/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2250 - accuracy: 0.9196 - recall_8: 0.9105 - precision_8: 0.9298 - val_loss: 0.1773 - val_accuracy: 0.9416 - val_recall_8: 0.9362 - val_precision_8: 0.9501\n",
      "Epoch 346/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2327 - accuracy: 0.9158 - recall_8: 0.9053 - precision_8: 0.9281 - val_loss: 0.1714 - val_accuracy: 0.9416 - val_recall_8: 0.9370 - val_precision_8: 0.9516\n",
      "Epoch 347/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2202 - accuracy: 0.9218 - recall_8: 0.9119 - precision_8: 0.9318 - val_loss: 0.1697 - val_accuracy: 0.9431 - val_recall_8: 0.9370 - val_precision_8: 0.9553\n",
      "Epoch 348/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2133 - accuracy: 0.9238 - recall_8: 0.9138 - precision_8: 0.9343 - val_loss: 0.1692 - val_accuracy: 0.9477 - val_recall_8: 0.9385 - val_precision_8: 0.9561\n",
      "Epoch 349/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2199 - accuracy: 0.9207 - recall_8: 0.9101 - precision_8: 0.9309 - val_loss: 0.1766 - val_accuracy: 0.9385 - val_recall_8: 0.9377 - val_precision_8: 0.9494\n",
      "Epoch 350/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2232 - accuracy: 0.9207 - recall_8: 0.9102 - precision_8: 0.9315 - val_loss: 0.1703 - val_accuracy: 0.9385 - val_recall_8: 0.9316 - val_precision_8: 0.9491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2207 - accuracy: 0.9205 - recall_8: 0.9098 - precision_8: 0.9319 - val_loss: 0.1821 - val_accuracy: 0.9285 - val_recall_8: 0.9247 - val_precision_8: 0.9391\n",
      "Epoch 352/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2249 - accuracy: 0.9207 - recall_8: 0.9110 - precision_8: 0.9317 - val_loss: 0.1717 - val_accuracy: 0.9370 - val_recall_8: 0.9301 - val_precision_8: 0.9483\n",
      "Epoch 353/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2217 - accuracy: 0.9202 - recall_8: 0.9088 - precision_8: 0.9309 - val_loss: 0.1709 - val_accuracy: 0.9439 - val_recall_8: 0.9370 - val_precision_8: 0.9516\n",
      "Epoch 354/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2218 - accuracy: 0.9200 - recall_8: 0.9102 - precision_8: 0.9315 - val_loss: 0.1722 - val_accuracy: 0.9400 - val_recall_8: 0.9331 - val_precision_8: 0.9529\n",
      "Epoch 355/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2172 - accuracy: 0.9237 - recall_8: 0.9133 - precision_8: 0.9343 - val_loss: 0.1766 - val_accuracy: 0.9408 - val_recall_8: 0.9354 - val_precision_8: 0.9500\n",
      "Epoch 356/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2170 - accuracy: 0.9231 - recall_8: 0.9130 - precision_8: 0.9340 - val_loss: 0.1723 - val_accuracy: 0.9439 - val_recall_8: 0.9385 - val_precision_8: 0.9547\n",
      "Epoch 357/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2171 - accuracy: 0.9241 - recall_8: 0.9139 - precision_8: 0.9337 - val_loss: 0.1721 - val_accuracy: 0.9462 - val_recall_8: 0.9385 - val_precision_8: 0.9547\n",
      "Epoch 358/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2221 - accuracy: 0.9207 - recall_8: 0.9110 - precision_8: 0.9317 - val_loss: 0.1797 - val_accuracy: 0.9354 - val_recall_8: 0.9308 - val_precision_8: 0.9431\n",
      "Epoch 359/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2257 - accuracy: 0.9194 - recall_8: 0.9090 - precision_8: 0.9299 - val_loss: 0.1640 - val_accuracy: 0.9454 - val_recall_8: 0.9408 - val_precision_8: 0.9548\n",
      "Epoch 360/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2176 - accuracy: 0.9211 - recall_8: 0.9120 - precision_8: 0.9328 - val_loss: 0.1755 - val_accuracy: 0.9400 - val_recall_8: 0.9331 - val_precision_8: 0.9499\n",
      "Epoch 361/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2238 - accuracy: 0.9206 - recall_8: 0.9104 - precision_8: 0.9319 - val_loss: 0.1773 - val_accuracy: 0.9400 - val_recall_8: 0.9354 - val_precision_8: 0.9463\n",
      "Epoch 362/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2176 - accuracy: 0.9220 - recall_8: 0.9124 - precision_8: 0.9329 - val_loss: 0.1739 - val_accuracy: 0.9424 - val_recall_8: 0.9362 - val_precision_8: 0.9486\n",
      "Epoch 363/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2191 - accuracy: 0.9214 - recall_8: 0.9113 - precision_8: 0.9323 - val_loss: 0.1765 - val_accuracy: 0.9447 - val_recall_8: 0.9385 - val_precision_8: 0.9472\n",
      "Epoch 364/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2286 - accuracy: 0.9187 - recall_8: 0.9078 - precision_8: 0.9290 - val_loss: 0.1739 - val_accuracy: 0.9400 - val_recall_8: 0.9324 - val_precision_8: 0.9506\n",
      "Epoch 365/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2234 - accuracy: 0.9205 - recall_8: 0.9092 - precision_8: 0.9318 - val_loss: 0.1762 - val_accuracy: 0.9377 - val_recall_8: 0.9331 - val_precision_8: 0.9470\n",
      "Epoch 366/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2175 - accuracy: 0.9234 - recall_8: 0.9134 - precision_8: 0.9340 - val_loss: 0.1748 - val_accuracy: 0.9347 - val_recall_8: 0.9324 - val_precision_8: 0.9440\n",
      "Epoch 367/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2118 - accuracy: 0.9245 - recall_8: 0.9152 - precision_8: 0.9358 - val_loss: 0.1618 - val_accuracy: 0.9431 - val_recall_8: 0.9370 - val_precision_8: 0.9523\n",
      "Epoch 368/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2210 - accuracy: 0.9220 - recall_8: 0.9125 - precision_8: 0.9334 - val_loss: 0.1684 - val_accuracy: 0.9447 - val_recall_8: 0.9377 - val_precision_8: 0.9539\n",
      "Epoch 369/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2199 - accuracy: 0.9213 - recall_8: 0.9118 - precision_8: 0.9324 - val_loss: 0.1641 - val_accuracy: 0.9470 - val_recall_8: 0.9385 - val_precision_8: 0.9547\n",
      "Epoch 370/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2198 - accuracy: 0.9219 - recall_8: 0.9134 - precision_8: 0.9329 - val_loss: 0.1694 - val_accuracy: 0.9416 - val_recall_8: 0.9362 - val_precision_8: 0.9531\n",
      "Epoch 371/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2210 - accuracy: 0.9214 - recall_8: 0.9117 - precision_8: 0.9317 - val_loss: 0.1790 - val_accuracy: 0.9393 - val_recall_8: 0.9347 - val_precision_8: 0.9478\n",
      "Epoch 372/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2219 - accuracy: 0.9192 - recall_8: 0.9094 - precision_8: 0.9310 - val_loss: 0.1728 - val_accuracy: 0.9416 - val_recall_8: 0.9347 - val_precision_8: 0.9537\n",
      "Epoch 373/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2238 - accuracy: 0.9216 - recall_8: 0.9119 - precision_8: 0.9331 - val_loss: 0.1721 - val_accuracy: 0.9477 - val_recall_8: 0.9393 - val_precision_8: 0.9547\n",
      "Epoch 374/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2143 - accuracy: 0.9243 - recall_8: 0.9149 - precision_8: 0.9355 - val_loss: 0.1757 - val_accuracy: 0.9354 - val_recall_8: 0.9308 - val_precision_8: 0.9468\n",
      "Epoch 375/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2188 - accuracy: 0.9210 - recall_8: 0.9120 - precision_8: 0.9323 - val_loss: 0.1819 - val_accuracy: 0.9408 - val_recall_8: 0.9316 - val_precision_8: 0.9491\n",
      "Epoch 376/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2100 - accuracy: 0.9244 - recall_8: 0.9142 - precision_8: 0.9351 - val_loss: 0.1992 - val_accuracy: 0.9324 - val_recall_8: 0.9301 - val_precision_8: 0.9380\n",
      "Epoch 377/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2172 - accuracy: 0.9243 - recall_8: 0.9156 - precision_8: 0.9345 - val_loss: 0.1792 - val_accuracy: 0.9377 - val_recall_8: 0.9301 - val_precision_8: 0.9446\n",
      "Epoch 378/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2114 - accuracy: 0.9249 - recall_8: 0.9150 - precision_8: 0.9345 - val_loss: 0.1668 - val_accuracy: 0.9431 - val_recall_8: 0.9385 - val_precision_8: 0.9487\n",
      "Epoch 379/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2127 - accuracy: 0.9244 - recall_8: 0.9138 - precision_8: 0.9346 - val_loss: 0.1628 - val_accuracy: 0.9462 - val_recall_8: 0.9400 - val_precision_8: 0.9547\n",
      "Epoch 380/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2222 - accuracy: 0.9224 - recall_8: 0.9109 - precision_8: 0.9321 - val_loss: 0.1891 - val_accuracy: 0.9385 - val_recall_8: 0.9285 - val_precision_8: 0.9512\n",
      "Epoch 381/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2101 - accuracy: 0.9257 - recall_8: 0.9167 - precision_8: 0.9361 - val_loss: 0.1782 - val_accuracy: 0.9362 - val_recall_8: 0.9308 - val_precision_8: 0.9424\n",
      "Epoch 382/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2124 - accuracy: 0.9252 - recall_8: 0.9150 - precision_8: 0.9349 - val_loss: 0.1845 - val_accuracy: 0.9362 - val_recall_8: 0.9324 - val_precision_8: 0.9477\n",
      "Epoch 383/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2239 - accuracy: 0.9195 - recall_8: 0.9094 - precision_8: 0.9306 - val_loss: 0.1790 - val_accuracy: 0.9393 - val_recall_8: 0.9316 - val_precision_8: 0.9498\n",
      "Epoch 384/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2203 - accuracy: 0.9200 - recall_8: 0.9113 - precision_8: 0.9311 - val_loss: 0.1636 - val_accuracy: 0.9477 - val_recall_8: 0.9400 - val_precision_8: 0.9562\n",
      "Epoch 385/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2205 - accuracy: 0.9224 - recall_8: 0.9115 - precision_8: 0.9326 - val_loss: 0.1741 - val_accuracy: 0.9439 - val_recall_8: 0.9370 - val_precision_8: 0.9509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2162 - accuracy: 0.9223 - recall_8: 0.9126 - precision_8: 0.9324 - val_loss: 0.1640 - val_accuracy: 0.9462 - val_recall_8: 0.9424 - val_precision_8: 0.9563\n",
      "Epoch 387/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2112 - accuracy: 0.9248 - recall_8: 0.9154 - precision_8: 0.9360 - val_loss: 0.1786 - val_accuracy: 0.9431 - val_recall_8: 0.9347 - val_precision_8: 0.9515\n",
      "Epoch 388/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2104 - accuracy: 0.9246 - recall_8: 0.9151 - precision_8: 0.9349 - val_loss: 0.1767 - val_accuracy: 0.9416 - val_recall_8: 0.9362 - val_precision_8: 0.9471\n",
      "Epoch 389/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2145 - accuracy: 0.9231 - recall_8: 0.9128 - precision_8: 0.9342 - val_loss: 0.1764 - val_accuracy: 0.9408 - val_recall_8: 0.9331 - val_precision_8: 0.9499\n",
      "Epoch 390/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2190 - accuracy: 0.9207 - recall_8: 0.9110 - precision_8: 0.9318 - val_loss: 0.1734 - val_accuracy: 0.9424 - val_recall_8: 0.9377 - val_precision_8: 0.9531\n",
      "Epoch 391/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2168 - accuracy: 0.9224 - recall_8: 0.9133 - precision_8: 0.9319 - val_loss: 0.1732 - val_accuracy: 0.9408 - val_recall_8: 0.9339 - val_precision_8: 0.9463\n",
      "Epoch 392/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2143 - accuracy: 0.9220 - recall_8: 0.9122 - precision_8: 0.9324 - val_loss: 0.1732 - val_accuracy: 0.9424 - val_recall_8: 0.9377 - val_precision_8: 0.9531\n",
      "Epoch 393/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2153 - accuracy: 0.9232 - recall_8: 0.9128 - precision_8: 0.9342 - val_loss: 0.1683 - val_accuracy: 0.9470 - val_recall_8: 0.9347 - val_precision_8: 0.9582\n",
      "Epoch 394/2500\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2138 - accuracy: 0.9238 - recall_8: 0.9147 - precision_8: 0.9340 - val_loss: 0.1609 - val_accuracy: 0.9393 - val_recall_8: 0.9331 - val_precision_8: 0.9499\n",
      "Epoch 395/2500\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2190 - accuracy: 0.9209 - recall_8: 0.9116 - precision_8: 0.9313 - val_loss: 0.1679 - val_accuracy: 0.9431 - val_recall_8: 0.9377 - val_precision_8: 0.9516\n",
      "Epoch 396/2500\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2178 - accuracy: 0.9218 - recall_8: 0.9122 - precision_8: 0.9324 - val_loss: 0.1726 - val_accuracy: 0.9454 - val_recall_8: 0.9393 - val_precision_8: 0.9502\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20)\n",
    "history = model.fit(X_train,y_train,batch_size=200,epochs=2500,\n",
    "                    validation_split=0.05,\n",
    "                    use_multiprocessing=True,workers=8,callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T11:56:02.083580Z",
     "start_time": "2021-12-26T11:55:59.953698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mlp_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"mlp_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T12:01:37.244329Z",
     "start_time": "2021-12-26T12:01:36.678547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      1626\n",
      "           1       0.92      0.96      0.94      1483\n",
      "           2       0.95      0.92      0.93      1326\n",
      "           3       0.91      0.90      0.91      1466\n",
      "           4       0.95      0.97      0.96      1326\n",
      "\n",
      "    accuracy                           0.94      7227\n",
      "   macro avg       0.94      0.94      0.94      7227\n",
      "weighted avg       0.94      0.94      0.94      7227\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test.argmax(axis=1),y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T11:58:03.871212Z",
     "start_time": "2021-12-26T11:58:03.861947Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "def unshorten_url(url):\n",
    "    session = requests.Session()  # so connections are recycled\n",
    "    resp = session.head(url, allow_redirects=True)\n",
    "    return resp.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T11:58:08.423933Z",
     "start_time": "2021-12-26T11:58:07.463265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://github.com/YD5463/UrlMalwareDetection'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
