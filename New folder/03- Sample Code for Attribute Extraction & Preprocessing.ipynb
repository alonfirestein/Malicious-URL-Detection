{"cells":[{"cell_type":"markdown","metadata":{},"source":["# <font color='red'> Sample Pre-processing of Web Content for Dataset Preparation </font>"]},{"cell_type":"markdown","metadata":{},"source":["## Initialisation Code"]},{"cell_type":"code","execution_count":1,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pysafebrowsing\n","  Downloading pysafebrowsing-0.1.1-py3-none-any.whl (5.7 kB)\n","Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from pysafebrowsing) (2.25.1)\n","Collecting configparser\n","  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->pysafebrowsing) (2020.12.5)\n","Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->pysafebrowsing) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->pysafebrowsing) (1.26.4)\n","Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->pysafebrowsing) (2.10)\n","Installing collected packages: configparser, pysafebrowsing\n","Successfully installed configparser-5.2.0 pysafebrowsing-0.1.1\n","Collecting tld\n","  Downloading tld-0.12.6-py38-none-any.whl (412 kB)\n","Installing collected packages: tld\n","Successfully installed tld-0.12.6\n","Requirement already satisfied: whois in c:\\programdata\\anaconda3\\lib\\site-packages (0.9.13)\n","Collecting geoip2\n","  Downloading geoip2-4.5.0-py2.py3-none-any.whl (26 kB)\n","Collecting maxminddb<3.0.0,>=2.2.0\n","  Downloading maxminddb-2.2.0.tar.gz (330 kB)\n","Requirement already satisfied: urllib3<2.0.0,>=1.25.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from geoip2) (1.26.4)\n","Requirement already satisfied: requests<3.0.0,>=2.24.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from geoip2) (2.25.1)\n","Collecting aiohttp<4.0.0,>=3.6.2\n","  Downloading aiohttp-3.8.1-cp38-cp38-win_amd64.whl (555 kB)\n","Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.6.2->geoip2) (20.3.0)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-5.2.0-cp38-cp38-win_amd64.whl (45 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp38-cp38-win_amd64.whl (122 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.2.0-cp38-cp38-win_amd64.whl (83 kB)\n","Collecting charset-normalizer<3.0,>=2.0\n","  Downloading charset_normalizer-2.0.9-py3-none-any.whl (39 kB)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.24.0->geoip2) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.24.0->geoip2) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.24.0->geoip2) (2020.12.5)\n","Building wheels for collected packages: maxminddb\n","  Building wheel for maxminddb (setup.py): started\n","  Building wheel for maxminddb (setup.py): finished with status 'done'\n","  Created wheel for maxminddb: filename=maxminddb-2.2.0-py2.py3-none-any.whl size=16344 sha256=df9c662bacbfc25db4092a4066146cfd347da916972d7ffef5998a06f0c18794\n","  Stored in directory: c:\\users\\yosef\\appdata\\local\\pip\\cache\\wheels\\79\\d1\\fc\\66fcd5c9bff68073fedbce2a0013180178817c4322f11abe8a\n","Successfully built maxminddb\n","Installing collected packages: multidict, frozenlist, yarl, charset-normalizer, async-timeout, aiosignal, maxminddb, aiohttp, geoip2\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 charset-normalizer-2.0.9 frozenlist-1.2.0 geoip2-4.5.0 maxminddb-2.2.0 multidict-5.2.0 yarl-1.7.2\n"]}],"source":["# Basic Libraries to be installed before moving ahead\n","!pip install pysafebrowsing\n","!pip install tld\n","!pip install whois\n","!pip install geoip2"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["# Basic Initialisation\n","import time\n","import pandas as pd\n","import numpy as np\n","pd.set_option('mode.chained_assignment', None) #Switch off warning"]},{"cell_type":"code","execution_count":37,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/geoipdatabase/GeoLite2-Country.mmdb\n","['geoipdatabase', 'preprocessingsampledata']\n","/kaggle/input/preprocessingsampledata/PreprocessingSampleData.csv\n","['geoipdatabase', 'preprocessingsampledata']\n"]}],"source":["#Verifying pathname of dataset before loading\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename));\n","        print(os.listdir(\"../input\"))"]},{"cell_type":"markdown","metadata":{},"source":["## Loading the Sample Web Content Crawled & Collected by MalCrawler"]},{"cell_type":"code","execution_count":29,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>url</th>\n","      <th>ip_add</th>\n","      <th>content</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>http://www.dutchthewiz.com/freeware/</td>\n","      <td>175.67.214.68</td>\n","      <td>Decay suggest in 1315.. Current constitution, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>http://www.collectiblejewels.com</td>\n","      <td>188.120.171.121</td>\n","      <td>breast addict nudger whash ky darkie catholics...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>http://www.deadlinedata.com</td>\n","      <td>193.51.170.1</td>\n","      <td>Nato's military stoic philosophy says to accep...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>http://www.mil.fi/maavoimat/kalustoesittely/00...</td>\n","      <td>13.237.35.44</td>\n","      <td>Night being newton. according to the formation...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>http://www.avclub.com/content/node/24539</td>\n","      <td>220.193.62.89</td>\n","      <td>34 per two children. if we exercise simple pra...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>http://www.ipl.org/div/potus/gwashington.html</td>\n","      <td>22.63.103.109</td>\n","      <td>In high-energy sixth congress, geneva. Desert ...</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>http://sharellmartin.biz</td>\n","      <td>102.44.184.56</td>\n","      <td>Forth. designation or headquarters to chicago'...</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>http://www.oatlands.org/</td>\n","      <td>206.161.206.80</td>\n","      <td>Ancient chinese gather sticks\". toponymist geo...</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>http://www.threshold21.com</td>\n","      <td>169.23.27.160</td>\n","      <td>Internet itself flagellated eukaryota. their c...</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>http://www.dauntlessmotors.com/</td>\n","      <td>139.90.4.65</td>\n","      <td>Climate change.an for inspiration to medieval ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows Ã— 3 columns</p>\n","</div>"],"text/plain":["                                                  url           ip_add  \\\n","0                http://www.dutchthewiz.com/freeware/    175.67.214.68   \n","1                    http://www.collectiblejewels.com  188.120.171.121   \n","2                         http://www.deadlinedata.com     193.51.170.1   \n","3   http://www.mil.fi/maavoimat/kalustoesittely/00...     13.237.35.44   \n","4            http://www.avclub.com/content/node/24539    220.193.62.89   \n","..                                                ...              ...   \n","95      http://www.ipl.org/div/potus/gwashington.html    22.63.103.109   \n","96                           http://sharellmartin.biz    102.44.184.56   \n","97                           http://www.oatlands.org/   206.161.206.80   \n","98                         http://www.threshold21.com    169.23.27.160   \n","99                    http://www.dauntlessmotors.com/      139.90.4.65   \n","\n","                                              content  \n","0   Decay suggest in 1315.. Current constitution, ...  \n","1   breast addict nudger whash ky darkie catholics...  \n","2   Nato's military stoic philosophy says to accep...  \n","3   Night being newton. according to the formation...  \n","4   34 per two children. if we exercise simple pra...  \n","..                                                ...  \n","95  In high-energy sixth congress, geneva. Desert ...  \n","96  Forth. designation or headquarters to chicago'...  \n","97  Ancient chinese gather sticks\". toponymist geo...  \n","98  Internet itself flagellated eukaryota. their c...  \n","99  Climate change.an for inspiration to medieval ...  \n","\n","[100 rows x 3 columns]"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["# Loading Dataset containing Raw Web Content, URL and IP Address (Output of MalCrawler)\n","def loadDataset():\n","    df = pd.read_csv(\"/kaggle/input/preprocessingsampledata/PreprocessingSampleData.csv\")\n","    return df\n","\n","df = loadDataset()\n","df = df[['url','ip_add', 'content']] # The three Columns of the initial data\n","df"]},{"cell_type":"code","execution_count":53,"metadata":{"trusted":true},"outputs":[],"source":["#Adding new blank columns to the dataframe df\n","df['geo_loc']=\"\"\n","df['url_len']=\"\"\n","df['js_len']=\"\"\n","df['js_obf_len']=\"\"\n","df['tld']=\"\"\n","df['who_is']=\"\"\n","df['https']=\"\"\n","df['label']=\"\"\n","df = df[['url','ip_add','geo_loc','url_len','js_len','js_obf_len','tld','who_is','https','content','label']]\n","#df"]},{"cell_type":"markdown","metadata":{},"source":["## Computing the 'geo_loc' Attribute from IP Address"]},{"cell_type":"code","execution_count":50,"metadata":{"trusted":true},"outputs":[],"source":["# Filling the 'geo_loc' column of dataframe \n","import os\n","import geoip2.database\n","import socket\n","import time\n","\n","reader = geoip2.database.Reader('/kaggle/input/geoipdatabase/GeoLite2-Country.mmdb')\n","\n","for x in df.index:\n","    try:\n","        ip_add = str(df['ip_add'][x])\n","        response = reader.country(ip_add)\n","        df['geo_loc'][x] = response.country.name\n","        #print(x, \"Finished,value is:\",response.country.name)   \n","    except Exception as msg:\n","        df['geo_loc'][x] = \"\"\n","        #print(x,\" Finished with Error Msg:\",msg)\n","\n","reader.close()\n","#df"]},{"cell_type":"markdown","metadata":{},"source":["## Computing 'url_len"]},{"cell_type":"code","execution_count":55,"metadata":{"trusted":true},"outputs":[],"source":["#Generating 'url_len' from 'url'\n","df['url_len'] = df['url'].str.len()\n","#df"]},{"cell_type":"markdown","metadata":{},"source":["## Computing 'js_len'"]},{"cell_type":"code","execution_count":56,"metadata":{"trusted":true},"outputs":[],"source":["import re       #importing regex for string selection and parsing\n","\n","def get_js_len_inKB(content): #Function for computing 'js_len from Web Content\n","    js=re.findall(r'<script>(.*?)</script>',content)\n","    complete_js=''.join(js)\n","    js_len = len(content.encode('utf-8'))/1000\n","    return js_len\n","for x in df.index: #Computing and Putting 'js_len' in Pandas Dataframe\n","    df['js_len'][x] = get_js_len_inKB(df['content'][x])\n","\n","#df"]},{"cell_type":"markdown","metadata":{},"source":["## Computing 'js_obf_len'"]},{"cell_type":"code","execution_count":58,"metadata":{"trusted":true},"outputs":[],"source":["# Computed using Selenium Emulator, thus will have to be run separately and then added\n","# Code given in https://github.com/lucianogiuseppe/JS-Auto-DeObfuscator/blob/master/jsado.py"]},{"cell_type":"markdown","metadata":{},"source":["## Computing 'tld' Attribute"]},{"cell_type":"code","execution_count":60,"metadata":{"trusted":true},"outputs":[],"source":["#Filling up TLD column\n","from tld import get_tld\n","\n","for x in df.index:       \n","    try:\n","        u = df.url[x]\n","        s = get_tld(str(u), fix_protocol=True)\n","        df['tld'][x] = s\n","    except:\n","        pass\n","#df"]},{"cell_type":"markdown","metadata":{},"source":["## Computing 'who_is' Attribute"]},{"cell_type":"code","execution_count":66,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["***Total Time taken --- 0.10448932647705078 seconds ---***\n"]}],"source":["#Whois processing\n","import whois\n","start_time = time.time()\n","\n","for x in df.index:  \n","    try:    \n","        domain = whois.query(df['url'][x])\n","        #print(domain.registrar)\n","        if len(str(domain.registrar)) >1 :\n","            df['who_is'][x]= 'complete'\n","        else:\n","            df['who_is'][x]= 'incomplete'\n","    except Exception as msg:\n","        #print(x,\", Error: \",msg)\n","        df['who_is'][x]= 'incomplete'\n","    #print(x,df['who_is'][x])\n","\n","print(\"***Total Time taken --- %s seconds ---***\" % (time.time() - start_time))\n","#df"]},{"cell_type":"code","execution_count":70,"metadata":{"trusted":true},"outputs":[],"source":["# Alternate Code for Computing using WHOIS API\n","from urllib.request  import  urlopen       # Importing url library\n","import  json                               # Importing the JSON Module\n","\n","url =  'https://www.bits-pilani.ac.in'  #A sample URL\n","apiKey = 'at_YC7W9LM2w1lQOCMmN0KUe3OU7B8Jc'\n","url = 'https://www.whoisxmlapi.com/whoisserver/WhoisService?'\\\n","    + 'domainName=' + url + '&apiKey=' + apiKey + \"&outputFormat=JSON\"\n","\n","whois_data= urlopen(url).read().decode('utf8') #WHO IS info returned by API\n","data=json.loads(whois_data) # Converting it from JSON to a Python Dict Object \n","#if data['registrarName']==\"\":\n","    #who_is = 'incomplete'\n","#else:\n","    #who_is = 'complete'\n","  \n","# Sample of one URL is shown here\n","# Similarly, who_is data is checked for all URLs in the dataset\n"]},{"cell_type":"markdown","metadata":{},"source":["## Computing the 'https' Attribute"]},{"cell_type":"code","execution_count":76,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["***Total Time taken --- 0.027629613876342773 seconds ---***\n"]}],"source":["# Filling the column https_status\n","import http.client\n","\n","start_time = time.time()\n","\n","for x in df.index:\n","    https_status= False\n","    try:\n","        conn = http.client.HTTPSConnection(df['url'][x])\n","        conn.request(\"HEAD\", \"/\")\n","        res = conn.getresponse()\n","        if res.status == 200 or res.status==301 or res.status==302:\n","            https_status= True   \n","        #print(x,res.status,res.reason,https_status)\n","    except Exception as msg:\n","        df['https'][x]= 'no'\n","        #print(x,\"Error: \",msg)\n","    finally:\n","        df['https'][x]= https_status\n","        #conn.close\n","\n","print(\"***Total Time taken --- %s seconds ---***\" % (time.time() - start_time))\n","#df"]},{"cell_type":"markdown","metadata":{},"source":["## Allocation of Class Label "]},{"cell_type":"code","execution_count":78,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["***Total Time taken --- 2.215198516845703 seconds ---***\n"]}],"source":["# Filling the label of training set from Google Safe Browising API\n","from pysafebrowsing import SafeBrowsing\n","KEY= \"AIzaSyABO6DPGmHpCs8U5ii1Efkp1dUPJHQfGpo\"\n","\n","start_time = time.time()\n","s = SafeBrowsing(KEY)\n","\n","for x in df.index:\n","    \n","    try:\n","        url = df['url'][x]\n","        r = s.lookup_urls([url])\n","        label=r[url]['malicious']    \n","        df['label']=label\n","        #print(x, label)\n","    except Exception as msg:\n","        df['label']=\"\"\n","        #print(x,\"Error: \",msg)\n","\n","print(\"***Total Time taken --- %s seconds ---***\" % (time.time() - start_time))\n","\n","#df"]},{"cell_type":"markdown","metadata":{},"source":["## Saving of Processed Data"]},{"cell_type":"code","execution_count":79,"metadata":{"trusted":true},"outputs":[],"source":["# Saving the file\n","#df.to_csv(\"Datasets/processed_webdata_sample.csv\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":4}
